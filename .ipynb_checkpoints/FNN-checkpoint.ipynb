{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8f5291-eb3e-488b-923f-e393c2879881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roy.xu23\\AppData\\Local\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\roy.xu23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\roy.xu23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Text Processing\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Embedding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Word Embeddings\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# For reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2d043a-82a8-4715-9ab5-a11dc745e8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  label  \n",
       "0  December 31, 2017       0  \n",
       "1  December 29, 2017       0  \n",
       "2  December 31, 2017       0  \n",
       "3  December 30, 2017       0  \n",
       "4  December 29, 2017       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Load Dataset\n",
    "# Paths to CSV files\n",
    "true_path = 'True.csv'\n",
    "fake_path = 'Fake.csv'\n",
    "\n",
    "# Load CSVs\n",
    "true_df = pd.read_csv(true_path)\n",
    "fake_df = pd.read_csv(fake_path)\n",
    "\n",
    "# Add a label column: 0 for True, 1 for Fake\n",
    "true_df['label'] = 0\n",
    "fake_df['label'] = 1\n",
    "\n",
    "# Combine the datasets\n",
    "df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66be6266-d64e-4970-9336-3a8d1990d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (44898, 5)\n",
      "\n",
      "Dataset columns: ['title', 'text', 'subject', 'date', 'label']\n",
      "\n",
      "Missing values:\n",
      " title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHFCAYAAADv8c1wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3K0lEQVR4nO3de1gWdf7/8dctyg0i3IHKSfGYZ10r3EU0VxQFTaXNXCt2Wd3M2qU0UsqrrLQszWOmlpmVWpraQc3WjZ+ayUZimhtbqGvuZqmXIKQIisrJ+f3Rcn+9AfUjooA+H9c11+XMvGfmPTcMvJwTNsuyLAEAAOCi6lR3AwAAALUBoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQk3lKVLl8pmszkHDw8PBQYGqk+fPpo2bZqysrLKLTN58mTZbLbL2s7p06c1efJkbd269bKWq2hbLVq00ODBgy9rPZfy3nvvae7cuRXOs9lsmjx5cpVur6p99tln6tatm7y8vGSz2bRu3boK63788UeXr/f5Q7du3S5rmzabTY888kgVdF/9Ro4cqRYtWlxwftnj5ELDxdZxLZz/9V21alW5+aXH088//1wN3eF6VLe6GwCqw5IlS9S+fXsVFRUpKytLKSkpmj59umbNmqXVq1erX79+ztoHHnhAAwYMuKz1nz59Ws8995wkKSIiwni5ymyrMt577z2lp6crISGh3LzU1FQ1bdr0qvdQWZZlafjw4Wrbtq3Wr18vLy8vtWvX7qLLjBkzRrGxsS7TGjRocDXbrNUGDRqk1NRUl2nh4eEaNmyYxo8f75xmt9uvdWsXNHHiRN19992qV69edbeC6xihCTekzp07u5xpuPvuu/XYY4/p9ttv19ChQ7V//34FBARIkpo2bXrVQ8Tp06dVv379a7KtS+nevXu1bv9Sjhw5ouPHj+uuu+5SZGSk0TLNmjWr8ftVkzRu3FiNGzcuNz0gIOCin2NJSYmKi4uveZgaOHCgPv30U73++usaM2bMNd02bixcngP+p1mzZpo9e7ZOnjypRYsWOadXdMlsy5YtioiIUMOGDeXp6almzZrp7rvv1unTp/Xjjz86f+E899xzzssHI0eOdFnfP//5Tw0bNky+vr5q3br1BbdVau3atfrVr34lDw8PtWrVSvPmzXOZX3pJ5ccff3SZvnXrVtlsNuelwoiICG3YsEE//fSTy6WWUhVdnktPT9edd94pX19feXh46JZbbtGyZcsq3M7KlSs1ceJEBQcHy8fHR/369dO+ffsu/MGfJyUlRZGRkfL29lb9+vXVo0cPbdiwwTl/8uTJzlA5YcKEK75EdPbsWY0fP1633HKLHA6H/Pz8FB4ero8//viSy1qWpaeeekr16tXT4sWLndNXr16t8PBweXl5qUGDBoqOjtY333xzyfVlZ2crPj5eHTt2VIMGDeTv76++ffvqiy++cKkrvSQ1a9YszZkzRy1btlSDBg0UHh6u7du3l1vv0qVL1a5dO9ntdnXo0EHvvPOOwSdzaaV9zJgxQy+88IJatmwpu92uzz//3Ph7sdTmzZsVGRkpHx8f1a9fXz179tRnn31m3Evfvn0VHR2tKVOm6OTJk5esv9T2du/eLZvNpg8++MA5bdeuXbLZbOrUqZPLumJiYhQaGuocv9jPBtR+hCbgPHfccYfc3Nz0j3/844I1P/74owYNGiR3d3e9/fbbSkpK0ksvvSQvLy8VFhYqKChISUlJkqRRo0YpNTVVqampeuaZZ1zWM3ToUN1888364IMP9Prrr1+0r7S0NCUkJOixxx7T2rVr1aNHDz366KOaNWvWZe/ja6+9pp49eyowMNDZW9lLMefbt2+fevTood27d2vevHlas2aNOnbsqJEjR2rGjBnl6p966in99NNPevPNN/XGG29o//79GjJkiEpKSi7aV3Jysvr27avc3Fy99dZbWrlypby9vTVkyBCtXr1a0i+XL9esWSPpl0tuqampWrt27SX3+dy5cyouLnYZLMtSQUGBjh8/rsTERK1bt04rV650nm28WLgoKChQbGysFixYoE8++USjR4+WJE2dOlX33XefOnbsqPfff1/vvvuuTp48qV69emnPnj0X7fH48eOSpEmTJmnDhg1asmSJWrVqpYiIiArvjXv11Ve1adMmzZ07VytWrFB+fr7uuOMO5ebmOmuWLl2qP//5z+rQoYM++ugjPf3005oyZYq2bNlyyc/M1Lx587RlyxbNmjVLn376qdq3b39Zyy9fvlxRUVHy8fHRsmXL9P7778vPz0/R0dGXFZymT5+un3/+WTNnzrzi7XXq1ElBQUHavHmzc7nNmzfL09NTe/bs0ZEjRyRJxcXFSk5Odl7Ov9TPBlwHLOAGsmTJEkuStXPnzgvWBAQEWB06dHCOT5o0yTr/UPnwww8tSVZaWtoF15GdnW1JsiZNmlRuXun6nn322QvOO1/z5s0tm81Wbnv9+/e3fHx8rPz8fJd9O3DggEvd559/bkmyPv/8c+e0QYMGWc2bN6+w97J933vvvZbdbrcOHjzoUjdw4ECrfv361okTJ1y2c8cdd7jUvf/++5YkKzU1tcLtlerevbvl7+9vnTx50jmtuLjY6ty5s9W0aVPr3LlzlmVZ1oEDByxJ1syZMy+6vvNrKxo2bdpUrr64uNgqKiqyRo0aZd16663lPpeHH37YOnbsmHX77bdbTZo0cfmaHDx40Kpbt641ZswYl+VOnjxpBQYGWsOHD79kvxX1EhkZad11113l9qlLly5WcXGxc/qOHTssSdbKlSsty7KskpISKzg42Lrtttucn51lWdaPP/5o1atX74Jf/wsp3f+yfbRu3doqLCx0qTX9XszPz7f8/PysIUOGuNSVlJRYXbt2tX7zm99ctKey3wt/+MMfLC8vLysjI8OyrP87nrKzsy97e3/84x+tVq1aOcf79etnjR492vL19bWWLVtmWZZlffnll5Yka+PGjZZlmf1sQO3GmSagDMuyLjr/lltukbu7ux588EEtW7ZMP/zwQ6W2c/fddxvXdurUSV27dnWZFhsbq7y8PP3zn/+s1PZNbdmyRZGRkQoJCXGZPnLkSJ0+fbrcWaqYmBiX8V/96leSpJ9++umC28jPz9dXX32lYcOGudyg7ebmpri4OB0+fNj4El9FHn30Ue3cudNlCAsLkyR98MEH6tmzpxo0aKC6deuqXr16euutt7R3795y6zlw4IDCw8OVl5en7du3u3xN/t//+38qLi7Wn/70J5czWh4eHurdu7fRk5Svv/66brvtNnl4eDh7+eyzzyrsZdCgQXJzc3OOl/2c9+3bpyNHjig2Ntbl8mvz5s3Vo0cPsw/OQExMTKVvvt62bZuOHz+uESNGuHxm586d04ABA7Rz507l5+cbr++FF15QUVGR8yGMK9leZGSkfvjhBx04cEBnz55VSkqKBgwYoD59+mjTpk2Sfjn7ZLfbdfvtt0uqup8NqLkITcB58vPzdezYMQUHB1+wpnXr1tq8ebP8/f318MMPq3Xr1mrdurVeeeWVy9pWUFCQcW1gYOAFpx07duyytnu5jh07VmGvpZ9R2e03bNjQZbz0puAzZ85ccBs5OTmyLOuytnM5mjZtqm7durkM3t7eWrNmjYYPH64mTZpo+fLlSk1N1c6dO3X//ffr7Nmz5dazY8cOff/997rnnnvK3bB/9OhRSdKvf/1r1atXz2VYvXr1JR97nzNnjv76178qLCxMH330kbZv366dO3dqwIABFX52l/qcSz+vi33vVIXL+T4uq/QzGzZsWLnPbPr06bIsy3nZ0kSLFi0UHx+vN998U/v377+i7ZVectu8ebNSUlJUVFSkvn37ql+/fs7LeJs3b1bPnj3l6ekpqep+NqDm4uk54DwbNmxQSUnJJV8T0KtXL/Xq1UslJSX6+uuvNX/+fCUkJCggIED33nuv0bYu591PmZmZF5xW+svTw8ND0i/325zvSt9R07BhQ2VkZJSbXnpfR6NGja5o/ZLk6+urOnXqXPXtlLV8+XK1bNlSq1evdvl6lP0MS91zzz0KDAzUxIkTde7cOT399NPOeaX9ffjhh2revHmleomIiNDChQtdppvc2FyR0u+Li33vVIWKvo9NvxdLP7P58+df8Km80qdYTT399NN6++239dRTT5W7aftytte0aVO1bdtWmzdvVosWLdStWzfddNNNioyMVHx8vL766itt37693FmtqvjZgJqL0AT8z8GDB5WYmCiHw6GHHnrIaBk3NzeFhYWpffv2WrFihf75z3/q3nvvNTq7cjl2796tf/3rXy6Xg9577z15e3vrtttukyTnU2Tffvuty3uL1q9fX259drvduLfIyEitXbtWR44ccTkD984776h+/fpV8ii/l5eXwsLCtGbNGs2aNcv5P/dz585p+fLlzl9gVc1ms8nd3d3lF39mZuZFn557+umn5e3trccee0z5+fmaNm2aJCk6Olp169bVf//738u69Hp+L2Uf1f/222+Vmppa7tKoiXbt2ikoKEgrV67UuHHjnPv4008/adu2bRc9m3qlTL8Xe/bsqZtuukl79uypsheHNmzYUBMmTNDEiRPLXdq73O3169dP77//vkJCQjRo0CBJUtu2bdWsWTM9++yzKioqcnmn2/ku9LMBtRuhCTek9PR05/0MWVlZ+uKLL7RkyRK5ublp7dq1Fb6jptTrr7+uLVu2aNCgQWrWrJnOnj2rt99+W9L/ndL39vZW8+bN9fHHHysyMlJ+fn5q1KhRpR+PDw4OVkxMjCZPnqygoCAtX75cmzZt0vTp01W/fn1Jv1wWateunRITE1VcXCxfX1+tXbtWKSkp5dbXpUsXrVmzRgsXLlRoaKjq1KlzwTdkT5o0SX/729/Up08fPfvss/Lz89OKFSu0YcMGzZgxQw6Ho1L7VNa0adPUv39/9enTR4mJiXJ3d9drr72m9PR0rVy58rLfym5i8ODBWrNmjeLj4zVs2DAdOnRIU6ZMUVBQUIWXd0o9+uijatCggR588EGdOnVK8+bNU4sWLfT8889r4sSJ+uGHHzRgwAD5+vrq6NGj2rFjh7y8vC54r01pL1OmTNGkSZPUu3dv7du3T88//7xatmyp4uLiy963OnXqaMqUKXrggQd01113afTo0Tpx4oQmT55cpZfnKmL6vdigQQPNnz9fI0aM0PHjxzVs2DD5+/srOztb//rXv5SdnV3uzJuJhIQEvfrqq/r000+vaHuRkZF67bXX9PPPP7u8QT8yMlJLliyRr6+vy+sGTH42oJar3vvQgWur9Kme0sHd3d3y9/e3evfubU2dOtXKysoqt0zZJ9pSU1Otu+66y2revLllt9uthg0bWr1797bWr1/vstzmzZutW2+91bLb7ZYka8SIES7rK32i52Lbsqxfnp4bNGiQ9eGHH1qdOnWy3N3drRYtWlhz5swpt/z3339vRUVFWT4+Plbjxo2tMWPGWBs2bCj39Nzx48etYcOGWTfddJNls9lctqkKnvr77rvvrCFDhlgOh8Nyd3e3unbtai1ZssSlpvTJqA8++MBleukTTmXrK/LFF19Yffv2tby8vCxPT0+re/fu1ieffFLh+i7n6bmL1b700ktWixYtLLvdbnXo0MFavHhxhV8HlXl6zLIsa+XKlVbdunWtP//5z1ZJSYllWZa1bt06q0+fPpaPj49lt9ut5s2bW8OGDbM2b9580V4LCgqsxMREq0mTJpaHh4d12223WevWrbNGjBjh8qTbxfapoq/dm2++abVp08Zyd3e32rZta7399tvl1mmi7P5f6rM1/V60LMtKTk62Bg0aZPn5+Vn16tWzmjRpYg0aNKjc91JZF+vhjTfecB7nZY810+3l5ORYderUsby8vFyeEFyxYoUlyRo6dKhLvenPBtReNsu6xKNCAAAA4Ok5AAAAE4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA4QmAAAAA7zcsgqdO3dOR44ckbe391V5ER8AAKh6lmXp5MmTCg4OVp06Fz6fRGiqQkeOHKnUnzsAAADV79ChQ+X+GPf5CE1VyNvbW9IvH7qPj081dwMAAEzk5eUpJCTE+Xv8QghNVaj0kpyPjw+hCQCAWuZSt9ZwIzgAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAIABQhMAAICButXdAADgF6GPv1PdLQA10q6Zf6ruFiRxpgkAAMAIoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMAAoQkAAMBA3epuAJcn9PF3qrsFoEbaNfNP1d0CgOscZ5oAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMVGtomjZtmn7961/L29tb/v7++t3vfqd9+/a51FiWpcmTJys4OFienp6KiIjQ7t27XWoKCgo0ZswYNWrUSF5eXoqJidHhw4ddanJychQXFyeHwyGHw6G4uDidOHHCpebgwYMaMmSIvLy81KhRI40dO1aFhYVXZd8BAEDtUq2hKTk5WQ8//LC2b9+uTZs2qbi4WFFRUcrPz3fWzJgxQ3PmzNGCBQu0c+dOBQYGqn///jp58qSzJiEhQWvXrtWqVauUkpKiU6dOafDgwSopKXHWxMbGKi0tTUlJSUpKSlJaWpri4uKc80tKSjRo0CDl5+crJSVFq1at0kcffaTx48dfmw8DAADUaDbLsqzqbqJUdna2/P39lZycrN/+9reyLEvBwcFKSEjQhAkTJP1yVikgIEDTp0/XQw89pNzcXDVu3Fjvvvuu7rnnHknSkSNHFBISor///e+Kjo7W3r171bFjR23fvl1hYWGSpO3btys8PFz//ve/1a5dO3366acaPHiwDh06pODgYEnSqlWrNHLkSGVlZcnHx+eS/efl5cnhcCg3N9eovjJCH3/nqqwXqO12zfxTdbdwxTi+gYpd7ePb9Pd3jbqnKTc3V5Lk5+cnSTpw4IAyMzMVFRXlrLHb7erdu7e2bdsmSdq1a5eKiopcaoKDg9W5c2dnTWpqqhwOhzMwSVL37t3lcDhcajp37uwMTJIUHR2tgoIC7dq1q8J+CwoKlJeX5zIAAIDrU40JTZZlady4cbr99tvVuXNnSVJmZqYkKSAgwKU2ICDAOS8zM1Pu7u7y9fW9aI2/v3+5bfr7+7vUlN2Or6+v3N3dnTVlTZs2zXmPlMPhUEhIyOXuNgAAqCVqTGh65JFH9O2332rlypXl5tlsNpdxy7LKTSurbE1F9ZWpOd+TTz6p3Nxc53Do0KGL9gQAAGqvGhGaxowZo/Xr1+vzzz9X06ZNndMDAwMlqdyZnqysLOdZocDAQBUWFionJ+eiNUePHi233ezsbJeastvJyclRUVFRuTNQpex2u3x8fFwGAABwfarW0GRZlh555BGtWbNGW7ZsUcuWLV3mt2zZUoGBgdq0aZNzWmFhoZKTk9WjRw9JUmhoqOrVq+dSk5GRofT0dGdNeHi4cnNztWPHDmfNV199pdzcXJea9PR0ZWRkOGs2btwou92u0NDQqt95AABQq9Stzo0//PDDeu+99/Txxx/L29vbeabH4XDI09NTNptNCQkJmjp1qtq0aaM2bdpo6tSpql+/vmJjY521o0aN0vjx49WwYUP5+fkpMTFRXbp0Ub9+/SRJHTp00IABAzR69GgtWrRIkvTggw9q8ODBateunSQpKipKHTt2VFxcnGbOnKnjx48rMTFRo0eP5gwSAACo3tC0cOFCSVJERITL9CVLlmjkyJGSpCeeeEJnzpxRfHy8cnJyFBYWpo0bN8rb29tZ//LLL6tu3boaPny4zpw5o8jISC1dulRubm7OmhUrVmjs2LHOp+xiYmK0YMEC53w3Nzdt2LBB8fHx6tmzpzw9PRUbG6tZs2Zdpb0HAAC1SY16T1Ntx3uagOrDe5qA6xfvaQIAAKhFCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGCE0AAAAGqjU0/eMf/9CQIUMUHBwsm82mdevWucwfOXKkbDaby9C9e3eXmoKCAo0ZM0aNGjWSl5eXYmJidPjwYZeanJwcxcXFyeFwyOFwKC4uTidOnHCpOXjwoIYMGSIvLy81atRIY8eOVWFh4dXYbQAAUAtVa2jKz89X165dtWDBggvWDBgwQBkZGc7h73//u8v8hIQErV27VqtWrVJKSopOnTqlwYMHq6SkxFkTGxurtLQ0JSUlKSkpSWlpaYqLi3POLykp0aBBg5Sfn6+UlBStWrVKH330kcaPH1/1Ow0AAGqlutW58YEDB2rgwIEXrbHb7QoMDKxwXm5urt566y29++676tevnyRp+fLlCgkJ0ebNmxUdHa29e/cqKSlJ27dvV1hYmCRp8eLFCg8P1759+9SuXTtt3LhRe/bs0aFDhxQcHCxJmj17tkaOHKkXX3xRPj4+VbjXAACgNqrx9zRt3bpV/v7+atu2rUaPHq2srCznvF27dqmoqEhRUVHOacHBwercubO2bdsmSUpNTZXD4XAGJknq3r27HA6HS03nzp2dgUmSoqOjVVBQoF27dl2wt4KCAuXl5bkMAADg+lSjQ9PAgQO1YsUKbdmyRbNnz9bOnTvVt29fFRQUSJIyMzPl7u4uX19fl+UCAgKUmZnprPH39y+3bn9/f5eagIAAl/m+vr5yd3d31lRk2rRpzvukHA6HQkJCrmh/AQBAzVWtl+cu5Z577nH+u3PnzurWrZuaN2+uDRs2aOjQoRdczrIs2Ww25/j5/76SmrKefPJJjRs3zjmel5dHcAIA4DpVo880lRUUFKTmzZtr//79kqTAwEAVFhYqJyfHpS4rK8t55igwMFBHjx4tt67s7GyXmrJnlHJyclRUVFTuDNT57Ha7fHx8XAYAAHB9qlWh6dixYzp06JCCgoIkSaGhoapXr542bdrkrMnIyFB6erp69OghSQoPD1dubq527NjhrPnqq6+Um5vrUpOenq6MjAxnzcaNG2W32xUaGnotdg0AANRw1Xp57tSpU/rPf/7jHD9w4IDS0tLk5+cnPz8/TZ48WXfffbeCgoL0448/6qmnnlKjRo101113SZIcDodGjRql8ePHq2HDhvLz81NiYqK6dOnifJquQ4cOGjBggEaPHq1FixZJkh588EENHjxY7dq1kyRFRUWpY8eOiouL08yZM3X8+HElJiZq9OjRnD0CAACSqjk0ff311+rTp49zvPT+oBEjRmjhwoX67rvv9M477+jEiRMKCgpSnz59tHr1anl7ezuXefnll1W3bl0NHz5cZ86cUWRkpJYuXSo3NzdnzYoVKzR27FjnU3YxMTEu74Zyc3PThg0bFB8fr549e8rT01OxsbGaNWvW1f4IAABALWGzLMuq7iauF3l5eXI4HMrNzb1qZ6hCH3/nqqwXqO12zfxTdbdwxTi+gYpd7ePb9Pd3rbqnCQAAoLoQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAwQmgAAAAxUKjT17dtXJ06cKDc9Ly9Pffv2vdKeAAAAapxKhaatW7eqsLCw3PSzZ8/qiy++uOKmAAAAapq6l1P87bffOv+9Z88eZWZmOsdLSkqUlJSkJk2aVF13AAAANcRlhaZbbrlFNptNNputwstwnp6emj9/fpU1BwAAUFNcVmg6cOCALMtSq1attGPHDjVu3Ng5z93dXf7+/nJzc6vyJgEAAKrbZYWm5s2bS5LOnTt3VZoBAACoqS4rNJ3v+++/19atW5WVlVUuRD377LNX3BgAAEBNUqnQtHjxYv31r39Vo0aNFBgYKJvN5pxns9kITQAA4LpTqdD0wgsv6MUXX9SECROquh8AAIAaqVLvacrJydHvf//7qu4FAACgxqpUaPr973+vjRs3VnUvAAAANValLs/dfPPNeuaZZ7R9+3Z16dJF9erVc5k/duzYKmkOAACgpqhUaHrjjTfUoEEDJScnKzk52WWezWYjNAEAgOtOpULTgQMHqroPAACAGq1S9zQBAADcaCp1pun++++/6Py33367Us0AAADUVJUKTTk5OS7jRUVFSk9P14kTJyr8Q74AAAC1XaVC09q1a8tNO3funOLj49WqVasrbgoAAKCmqbJ7murUqaPHHntML7/8clWtEgAAoMao0hvB//vf/6q4uLgqVwkAAFAjVOry3Lhx41zGLctSRkaGNmzYoBEjRlRJYwAAADVJpULTN9984zJep04dNW7cWLNnz77kk3UAAAC1UaVC0+eff17VfQAAANRolQpNpbKzs7Vv3z7ZbDa1bdtWjRs3rqq+AAAAapRK3Qien5+v+++/X0FBQfrtb3+rXr16KTg4WKNGjdLp06erukcAAIBqV6nQNG7cOCUnJ+uTTz7RiRMndOLECX388cdKTk7W+PHjq7pHAACAalepy3MfffSRPvzwQ0VERDin3XHHHfL09NTw4cO1cOHCquoPAACgRqjUmabTp08rICCg3HR/f38uzwEAgOtSpUJTeHi4Jk2apLNnzzqnnTlzRs8995zCw8OrrDkAAICaolKX5+bOnauBAweqadOm6tq1q2w2m9LS0mS327Vx48aq7hEAAKDaVSo0denSRfv379fy5cv173//W5Zl6d5779Uf/vAHeXp6VnWPAAAA1a5SoWnatGkKCAjQ6NGjXaa//fbbys7O1oQJE6qkOQAAgJqiUvc0LVq0SO3bty83vVOnTnr99devuCkAAICaplKhKTMzU0FBQeWmN27cWBkZGVfcFAAAQE1TqdAUEhKiL7/8stz0L7/8UsHBwVfcFAAAQE1TqXuaHnjgASUkJKioqEh9+/aVJH322Wd64okneCM4AAC4LlUqND3xxBM6fvy44uPjVVhYKEny8PDQhAkT9OSTT1ZpgwAAADVBpUKTzWbT9OnT9cwzz2jv3r3y9PRUmzZtZLfbq7o/AACAGqFSoalUgwYN9Otf/7qqegEAAKixKnUjOAAAwI2G0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCA0AQAAGCgWkPTP/7xDw0ZMkTBwcGy2Wxat26dy3zLsjR58mQFBwfL09NTERER2r17t0tNQUGBxowZo0aNGsnLy0sxMTE6fPiwS01OTo7i4uLkcDjkcDgUFxenEydOuNQcPHhQQ4YMkZeXlxo1aqSxY8c6/64eAABAtYam/Px8de3aVQsWLKhw/owZMzRnzhwtWLBAO3fuVGBgoPr376+TJ086axISErR27VqtWrVKKSkpOnXqlAYPHqySkhJnTWxsrNLS0pSUlKSkpCSlpaUpLi7OOb+kpESDBg1Sfn6+UlJStGrVKn300UcaP3781dt5AABQq1zR3567UgMHDtTAgQMrnGdZlubOnauJEydq6NChkqRly5YpICBA7733nh566CHl5ubqrbfe0rvvvqt+/fpJkpYvX66QkBBt3rxZ0dHR2rt3r5KSkrR9+3aFhYVJkhYvXqzw8HDt27dP7dq108aNG7Vnzx4dOnRIwcHBkqTZs2dr5MiRevHFF+Xj43MNPg0AAFCT1dh7mg4cOKDMzExFRUU5p9ntdvXu3Vvbtm2TJO3atUtFRUUuNcHBwercubOzJjU1VQ6HwxmYJKl79+5yOBwuNZ07d3YGJkmKjo5WQUGBdu3adcEeCwoKlJeX5zIAAIDrU40NTZmZmZKkgIAAl+kBAQHOeZmZmXJ3d5evr+9Fa/z9/cut39/f36Wm7HZ8fX3l7u7urKnItGnTnPdJORwOhYSEXOZeAgCA2qLGhqZSNpvNZdyyrHLTyipbU1F9ZWrKevLJJ5Wbm+scDh06dNG+AABA7VVjQ1NgYKAklTvTk5WV5TwrFBgYqMLCQuXk5Fy05ujRo+XWn52d7VJTdjs5OTkqKioqdwbqfHa7XT4+Pi4DAAC4PtXY0NSyZUsFBgZq06ZNzmmFhYVKTk5Wjx49JEmhoaGqV6+eS01GRobS09OdNeHh4crNzdWOHTucNV999ZVyc3NdatLT05WRkeGs2bhxo+x2u0JDQ6/qfgIAgNqhWp+eO3XqlP7zn/84xw8cOKC0tDT5+fmpWbNmSkhI0NSpU9WmTRu1adNGU6dOVf369RUbGytJcjgcGjVqlMaPH6+GDRvKz89PiYmJ6tKli/Npug4dOmjAgAEaPXq0Fi1aJEl68MEHNXjwYLVr106SFBUVpY4dOyouLk4zZ87U8ePHlZiYqNGjR3P2CAAASKrm0PT111+rT58+zvFx48ZJkkaMGKGlS5fqiSee0JkzZxQfH6+cnByFhYVp48aN8vb2di7z8ssvq27duho+fLjOnDmjyMhILV26VG5ubs6aFStWaOzYsc6n7GJiYlzeDeXm5qYNGzYoPj5ePXv2lKenp2JjYzVr1qyr/REAAIBawmZZllXdTVwv8vLy5HA4lJube9XOUIU+/s5VWS9Q2+2a+afqbuGKcXwDFbvax7fp7+8ae08TAABATUJoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMEBoAgAAMFCjQ9PkyZNls9lchsDAQOd8y7I0efJkBQcHy9PTUxEREdq9e7fLOgoKCjRmzBg1atRIXl5eiomJ0eHDh11qcnJyFBcXJ4fDIYfDobi4OJ04ceJa7CIAAKglanRokqROnTopIyPDOXz33XfOeTNmzNCcOXO0YMEC7dy5U4GBgerfv79OnjzprElISNDatWu1atUqpaSk6NSpUxo8eLBKSkqcNbGxsUpLS1NSUpKSkpKUlpamuLi4a7qfAACgZqtb3Q1cSt26dV3OLpWyLEtz587VxIkTNXToUEnSsmXLFBAQoPfee08PPfSQcnNz9dZbb+ndd99Vv379JEnLly9XSEiINm/erOjoaO3du1dJSUnavn27wsLCJEmLFy9WeHi49u3bp3bt2l27nQUAADVWjT/TtH//fgUHB6tly5a699579cMPP0iSDhw4oMzMTEVFRTlr7Xa7evfurW3btkmSdu3apaKiIpea4OBgde7c2VmTmpoqh8PhDEyS1L17dzkcDmcNAABAjT7TFBYWpnfeeUdt27bV0aNH9cILL6hHjx7avXu3MjMzJUkBAQEuywQEBOinn36SJGVmZsrd3V2+vr7lakqXz8zMlL+/f7lt+/v7O2supKCgQAUFBc7xvLy8y99JAABQK9To0DRw4EDnv7t06aLw8HC1bt1ay5YtU/fu3SVJNpvNZRnLsspNK6tsTUX1JuuZNm2annvuuUvuBwAAqP1q/OW583l5ealLly7av3+/8z6nsmeDsrKynGefAgMDVVhYqJycnIvWHD16tNy2srOzy53FKuvJJ59Ubm6uczh06FCl9w0AANRstSo0FRQUaO/evQoKClLLli0VGBioTZs2OecXFhYqOTlZPXr0kCSFhoaqXr16LjUZGRlKT0931oSHhys3N1c7duxw1nz11VfKzc111lyI3W6Xj4+PywAAAK5PNfryXGJiooYMGaJmzZopKytLL7zwgvLy8jRixAjZbDYlJCRo6tSpatOmjdq0aaOpU6eqfv36io2NlSQ5HA6NGjVK48ePV8OGDeXn56fExER16dLF+TRdhw4dNGDAAI0ePVqLFi2SJD344IMaPHgwT84BAACnGh2aDh8+rPvuu08///yzGjdurO7du2v79u1q3ry5JOmJJ57QmTNnFB8fr5ycHIWFhWnjxo3y9vZ2ruPll19W3bp1NXz4cJ05c0aRkZFaunSp3NzcnDUrVqzQ2LFjnU/ZxcTEaMGCBdd2ZwEAQI1msyzLqu4mrhd5eXlyOBzKzc29apfqQh9/56qsF6jtds38U3W3cMU4voGKXe3j2/T3d626pwkAAKC6EJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJoAAAAMEJrKeO2119SyZUt5eHgoNDRUX3zxRXW3BAAAagBC03lWr16thIQETZw4Ud9884169eqlgQMH6uDBg9XdGgAAqGaEpvPMmTNHo0aN0gMPPKAOHTpo7ty5CgkJ0cKFC6u7NQAAUM0ITf9TWFioXbt2KSoqymV6VFSUtm3bVk1dAQCAmqJudTdQU/z8888qKSlRQECAy/SAgABlZmZWuExBQYEKCgqc47m5uZKkvLy8q9ZnScGZq7ZuoDa7msfdtcLxDVTsah/fpeu3LOuidYSmMmw2m8u4ZVnlppWaNm2annvuuXLTQ0JCrkpvAC7MMf8v1d0CgKvkWh3fJ0+elMPhuOB8QtP/NGrUSG5ubuXOKmVlZZU7+1TqySef1Lhx45zj586d0/Hjx9WwYcMLBi1cP/Ly8hQSEqJDhw7Jx8enutsBUIU4vm8slmXp5MmTCg4Ovmgdoel/3N3dFRoaqk2bNumuu+5yTt+0aZPuvPPOCpex2+2y2+0u02666aar2SZqIB8fH36oAtcpju8bx8XOMJUiNJ1n3LhxiouLU7du3RQeHq433nhDBw8e1F/+wml/AABudISm89xzzz06duyYnn/+eWVkZKhz5876+9//rubNm1d3awAAoJoRmsqIj49XfHx8dbeBWsBut2vSpEnlLtECqP04vlERm3Wp5+sAAADAyy0BAABMEJoAAAAMEJoAAAAMEJoAAChj6dKlvHcP5RCacMOz2WwXHUaOHFndLQKopJEjR1Z4XP/nP/+p7tZQC/HKAdzwMjIynP9evXq1nn32We3bt885zdPT06W+qKhI9erVu2b9AbgyAwYM0JIlS1ymNW7cuJq6QW3GmSbc8AIDA52Dw+GQzWZzjp89e1Y33XST3n//fUVERMjDw0PLly/X5MmTdcstt7isZ+7cuWrRooXLtCVLlqhDhw7y8PBQ+/bt9dprr127HQMg6Zd3Lp1/nAcGBuqVV15Rly5d5OXlpZCQEMXHx+vUqVMXXMexY8f0m9/8RjExMTp79qwsy9KMGTPUqlUreXp6qmvXrvrwww+v4V6hOhCaAAMTJkzQ2LFjtXfvXkVHRxsts3jxYk2cOFEvvvii9u7dq6lTp+qZZ57RsmXLrnK3AC6lTp06mjdvntLT07Vs2TJt2bJFTzzxRIW1hw8fVq9evdS+fXutWbNGHh4eevrpp7VkyRItXLhQu3fv1mOPPaY//vGPSk5OvsZ7gmuJy3OAgYSEBA0dOvSylpkyZYpmz57tXK5ly5bas2ePFi1apBEjRlyNNgFU4G9/+5saNGjgHB84cKA++OAD53jLli01ZcoU/fWvfy13Nvj7779X//79deedd+qVV16RzWZTfn6+5syZoy1btig8PFyS1KpVK6WkpGjRokXq3bv3tdkxXHOEJsBAt27dLqs+Oztbhw4d0qhRozR69Gjn9OLiYqO/pA2g6vTp00cLFy50jnt5eenzzz/X1KlTtWfPHuXl5am4uFhnz55Vfn6+vLy8JElnzpzR7bffrvvuu0+vvPKKc/k9e/bo7Nmz6t+/v8t2CgsLdeutt16bnUK1IDQBBkp/iJaqU6eOyv4FoqKiIue/z507J+mXS3RhYWEudW5ublepSwAV8fLy0s033+wc/+mnn3THHXfoL3/5i6ZMmSI/Pz+lpKRo1KhRLsex3W5Xv379tGHDBj3++ONq2rSppP87vjds2KAmTZq4bIu/VXd9IzQBldC4cWNlZmbKsizZbDZJUlpamnN+QECAmjRpoh9++EF/+MMfqqlLABX5+uuvVVxcrNmzZ6tOnV9u7X3//ffL1dWpU0fvvvuuYmNj1bdvX23dulXBwcHq2LGj7Ha7Dh48yKW4GwyhCaiEiIgIZWdna8aMGRo2bJiSkpL06aefysfHx1kzefJkjR07Vj4+Pho4cKAKCgr09ddfKycnR+PGjavG7oEbW+vWrVVcXKz58+dryJAh+vLLL/X6669XWOvm5qYVK1bovvvucwanwMBAJSYm6rHHHtO5c+d0++23Ky8vT9u2bVODBg24Z/E6xtNzQCV06NBBr732ml599VV17dpVO3bsUGJiokvNAw88oDfffFNLly5Vly5d1Lt3by1dulQtW7aspq4BSNItt9yiOXPmaPr06ercubNWrFihadOmXbC+bt26WrlypTp16qS+ffsqKytLU6ZM0bPPPqtp06apQ4cOio6O1ieffMLxfZ2zWWVvzAAAAEA5nGkCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCcMOIiIhQQkKCUe3WrVtls9l04sSJK9pmixYtNHfu3CtaB4CagdAEAABggNAEAABggNAE4Ia0fPlydevWTd7e3goMDFRsbKyysrLK1X355Zfq2rWrPDw8FBYWpu+++85l/rZt2/Tb3/5Wnp6eCgkJ0dixY5Wfn3+tdgPANURoAnBDKiws1JQpU/Svf/1L69at04EDBzRy5MhydY8//rhmzZqlnTt3yt/fXzExMSoqKpIkfffdd4qOjtbQoUP17bffavXq1UpJSdEjjzxyjfcGwLVQt7obAIDqcP/99zv/3apVK82bN0+/+c1vdOrUKTVo0MA5b9KkSerfv78kadmyZWratKnWrl2r4cOHa+bMmYqNjXXeXN6mTRvNmzdPvXv31sKFC+Xh4XFN9wnA1cWZJgA3pG+++UZ33nmnmjdvLm9vb0VEREiSDh486FIXHh7u/Lefn5/atWunvXv3SpJ27dqlpUuXqkGDBs4hOjpa586d04EDB67ZvgC4NjjTBOCGk5+fr6ioKEVFRWn58uVq3LixDh48qOjoaBUWFl5yeZvNJkk6d+6cHnroIY0dO7ZcTbNmzaq8bwDVi9AE4Ibz73//Wz///LNeeuklhYSESJK+/vrrCmu3b9/uDEA5OTn6/vvv1b59e0nSbbfdpt27d+vmm2++No0DqFZcngNww2nWrJnc3d01f/58/fDDD1q/fr2mTJlSYe3zzz+vzz77TOnp6Ro5cqQaNWqk3/3ud5KkCRMmKDU1VQ8//LDS0tK0f/9+rV+/XmPGjLmGewPgWiE0AbjhNG7cWEuXLtUHH3ygjh076qWXXtKsWbMqrH3ppZf06KOPKjQ0VBkZGVq/fr3c3d0lSb/61a+UnJys/fv3q1evXrr11lv1zDPPKCgo6FruDoBrxGZZllXdTQAAANR0nGkCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAwQGgCAAAw8P8BFl/HfZobQhgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample True News:\n",
      "WASHINGTON (Reuters) - The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress. President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense “discretionary” spending on programs that support education, scientific research, infrastructure, public health and environmental protection. “The (Trump) administration has already been willing to say: ‘We’re going to increase non-defense discretionary spending ... by about 7 percent,’” Meadows, chairman of the small but influential House Freedom Caucus, said on the program. “Now, Democrats are saying that’s not enough, we need to give the government a pay raise of 10 to 11 percent. For a fiscal conservative, I don’t see where the rationale is. ... Eventually you run out of other people’s money,” he said. Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt. “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S. Representative Joseph Crowley said on CBS. Crowley said the Republican tax bill would require the  United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich. “This is one of the least ... fiscally responsible bills we’ve ever seen passed in the history of the House of Representatives. I think we’re going to be paying for this for many, many years to come,” Crowley said. Republicans insist the tax package, the biggest U.S. tax overhaul in more than 30 years,  will boost the economy and job growth. House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or “entitlement reform,” as the party often calls it, would be a top Republican priority in 2018. In Republican parlance, “entitlement” programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy. Democrats seized on Ryan’s early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs. But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown. Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the “Dreamers,” people brought illegally to the country as children. Trump in September put a March 2018 expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits. The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers. Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. “We need to do DACA clean,” she said.  On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. 6 and 7, the White House said. Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid. \n",
      "\n",
      "Sample Fake News:\n",
      "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.  2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year. 2018 will be a great year for America!  Donald J. Trump (@realDonaldTrump) December 31, 2017Trump s tweet went down about as welll as you d expect.What kind of president sends a New Year s greeting like this despicable, petty, infantile gibberish? Only Trump! His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year!  Bishop Talbert Swan (@TalbertSwan) December 31, 2017no one likes you  Calvin (@calvinstowell) December 31, 2017Your impeachment would make 2018 a great year for America, but I ll also accept regaining control of Congress.  Miranda Yaver (@mirandayaver) December 31, 2017Do you hear yourself talk? When you have to include that many people that hate you you have to wonder? Why do the they all hate me?  Alan Sandoval (@AlanSandoval13) December 31, 2017Who uses the word Haters in a New Years wish??  Marlene (@marlene399) December 31, 2017You can t just say happy new year?  Koren pollitt (@Korencarpenter) December 31, 2017Here s Trump s New Year s Eve tweet from 2016.Happy New Year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. Love!  Donald J. Trump (@realDonaldTrump) December 31, 2016This is nothing new for Trump. He s been doing this for years.Trump has directed messages to his  enemies  and  haters  for New Year s, Easter, Thanksgiving, and the anniversary of 9/11. pic.twitter.com/4FPAe2KypA  Daniel Dale (@ddale8) December 31, 2017Trump s holiday tweets are clearly not presidential.How long did he work at Hallmark before becoming President?  Steven Goodine (@SGoodine) December 31, 2017He s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  Roy Schulze (@thbthttt) December 31, 2017Who, apart from a teenager uses the term haters?  Wendy (@WendyWhistles) December 31, 2017he s a fucking 5 year old  Who Knows (@rainyday80) December 31, 2017So, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.Photo by Andrew Burton/Getty Images.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Exploration\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nDataset columns:\", df.columns.tolist())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Distribution of labels\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title('Distribution of Fake and True News')\n",
    "plt.xticks([0,1], ['True', 'Fake'])\n",
    "plt.show()\n",
    "\n",
    "# Display some sample texts\n",
    "print(\"\\nSample True News:\")\n",
    "print(df[df['label'] == 0]['text'].iloc[0])\n",
    "\n",
    "print(\"\\nSample Fake News:\")\n",
    "print(df[df['label'] == 1]['text'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d47aaa-05fc-45c1-8f98-122ee8066e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data Preprocessing Functions\n",
    "# Initialize stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text, remove_stopwords=True, to_lower=True, remove_punctuation=True, perform_stemming=False, perform_lemmatization=False):\n",
    "    # Remove HTML tags if any\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    if remove_punctuation:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Lowercase\n",
    "    if to_lower:\n",
    "        text = text.lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    if remove_stopwords:\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Optional: Stemming\n",
    "    if perform_stemming:\n",
    "        from nltk.stem import PorterStemmer\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Optional: Lemmatization\n",
    "    if perform_lemmatization:\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d98417f-cce2-44fe-87e9-a02bf513e51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying preprocessing: Basic\n",
      "Applying preprocessing: Lowercase\n",
      "Applying preprocessing: Lowercase & Remove Punctuation\n",
      "Applying preprocessing: Lowercase, Remove Punctuation & Stopwords\n",
      "Applying preprocessing: Full Preprocessing\n",
      "\n",
      "Sample text after 'Basic' preprocessing:\n",
      "WASHINGTON ( Reuters ) - The head of a conservative Republican faction in the U.S. Congress , who voted this month for a huge expansion of the national debt to pay for tax cuts , called himself a “ fiscal conservative ” on Sunday and urged budget restraint in . In keeping with a sharp pivot under way among Republicans , U.S. Representative Mark Meadows , speaking on CBS ’ “ Face the Nation , ” drew a hard line on federal spending , which lawmakers are bracing to do battle over in January . When they return from the holidays on Wednesday , lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues , such as immigration policy , even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress . President Donald Trump and his Republicans want a big budget increase in military spending , while Democrats also want proportional increases for non-defense “ discretionary ” spending on programs that support education , scientific research , infrastructure , public health and environmental protection . “ The ( Trump ) administration has already been willing to say : ‘ We ’ re going to increase non-defense discretionary spending ... by about percent , ’ ” Meadows , chairman of the small but influential House Freedom Caucus , said on the program . “ Now , Democrats are saying that ’ s not enough , we need to give the government a pay raise of to percent . For a fiscal conservative , I don ’ t see where the rationale is . ... Eventually you run out of other people ’ s money , ” he said . Meadows was among Republicans who voted in late December for their party ’ s debt-financed tax overhaul , which is expected to balloon the federal budget deficit and add about $ . trillion over years to the $ trillion national debt . “ It ’ s interesting to hear Mark talk about fiscal responsibility , ” Democratic U.S. Representative Joseph Crowley said on CBS . Crowley said the Republican tax bill would require the United States to borrow $ . trillion , to be paid off by future generations , to finance tax cuts for corporations and the rich . “ This is one of the least ... fiscally responsible bills we ’ ve ever seen passed in the history of the House of Representatives . I think we ’ re going to be paying for this for many , many years to come , ” Crowley said . Republicans insist the tax package , the biggest U.S. tax overhaul in more than years , will boost the economy and job growth . House Speaker Paul Ryan , who also supported the tax bill , recently went further than Meadows , making clear in a radio interview that welfare or “ entitlement reform , ” as the party often calls it , would be a top Republican priority in . In Republican parlance , “ entitlement ” programs mean food stamps , housing assistance , Medicare and Medicaid health insurance for the elderly , poor and disabled , as well as other programs created by Washington to assist the needy . Democrats seized on Ryan ’ s early December remarks , saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs . But the goals of House Republicans may have to take a back seat to the Senate , where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown . Democrats will use their leverage in the Senate , which Republicans narrowly control , to defend both discretionary non-defense programs and social spending , while tackling the issue of the “ Dreamers , ” people brought illegally to the country as children . Trump in September put a March expiration date on the Deferred Action for Childhood Arrivals , or DACA , program , which protects the young immigrants from deportation and provides them with work permits . The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers . Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives , such as wall funding . “ We need to do DACA clean , ” she said . On Wednesday , Trump aides will meet with congressional leaders to discuss those issues . That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. and , the White House said . Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott , who wants more emergency aid . The House has passed an $ billion aid package after hurricanes in Florida , Texas and Puerto Rico , and wildfires in California . The package far exceeded the $ billion requested by the Trump administration . The Senate has not yet voted on the aid .\n",
      "\n",
      "Sample text after 'Lowercase' preprocessing:\n",
      "washington ( reuters ) - the head of a conservative republican faction in the u.s. congress , who voted this month for a huge expansion of the national debt to pay for tax cuts , called himself a “ fiscal conservative ” on sunday and urged budget restraint in . in keeping with a sharp pivot under way among republicans , u.s. representative mark meadows , speaking on cbs ’ “ face the nation , ” drew a hard line on federal spending , which lawmakers are bracing to do battle over in january . when they return from the holidays on wednesday , lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues , such as immigration policy , even as the november congressional election campaigns approach in which republicans will seek to keep control of congress . president donald trump and his republicans want a big budget increase in military spending , while democrats also want proportional increases for non-defense “ discretionary ” spending on programs that support education , scientific research , infrastructure , public health and environmental protection . “ the ( trump ) administration has already been willing to say : ‘ we ’ re going to increase non-defense discretionary spending ... by about percent , ’ ” meadows , chairman of the small but influential house freedom caucus , said on the program . “ now , democrats are saying that ’ s not enough , we need to give the government a pay raise of to percent . for a fiscal conservative , i don ’ t see where the rationale is . ... eventually you run out of other people ’ s money , ” he said . meadows was among republicans who voted in late december for their party ’ s debt-financed tax overhaul , which is expected to balloon the federal budget deficit and add about $ . trillion over years to the $ trillion national debt . “ it ’ s interesting to hear mark talk about fiscal responsibility , ” democratic u.s. representative joseph crowley said on cbs . crowley said the republican tax bill would require the united states to borrow $ . trillion , to be paid off by future generations , to finance tax cuts for corporations and the rich . “ this is one of the least ... fiscally responsible bills we ’ ve ever seen passed in the history of the house of representatives . i think we ’ re going to be paying for this for many , many years to come , ” crowley said . republicans insist the tax package , the biggest u.s. tax overhaul in more than years , will boost the economy and job growth . house speaker paul ryan , who also supported the tax bill , recently went further than meadows , making clear in a radio interview that welfare or “ entitlement reform , ” as the party often calls it , would be a top republican priority in . in republican parlance , “ entitlement ” programs mean food stamps , housing assistance , medicare and medicaid health insurance for the elderly , poor and disabled , as well as other programs created by washington to assist the needy . democrats seized on ryan ’ s early december remarks , saying they showed republicans would try to pay for their tax overhaul by seeking spending cuts for social programs . but the goals of house republicans may have to take a back seat to the senate , where the votes of some democrats will be needed to approve a budget and prevent a government shutdown . democrats will use their leverage in the senate , which republicans narrowly control , to defend both discretionary non-defense programs and social spending , while tackling the issue of the “ dreamers , ” people brought illegally to the country as children . trump in september put a march expiration date on the deferred action for childhood arrivals , or daca , program , which protects the young immigrants from deportation and provides them with work permits . the president has said in recent twitter messages he wants funding for his proposed mexican border wall and other immigration law changes in exchange for agreeing to help the dreamers . representative debbie dingell told cbs she did not favor linking that issue to other policy objectives , such as wall funding . “ we need to do daca clean , ” she said . on wednesday , trump aides will meet with congressional leaders to discuss those issues . that will be followed by a weekend of strategy sessions for trump and republican leaders on jan. and , the white house said . trump was also scheduled to meet on sunday with florida republican governor rick scott , who wants more emergency aid . the house has passed an $ billion aid package after hurricanes in florida , texas and puerto rico , and wildfires in california . the package far exceeded the $ billion requested by the trump administration . the senate has not yet voted on the aid .\n",
      "\n",
      "Sample text after 'Lowercase & Remove Punctuation' preprocessing:\n",
      "washington reuters the head of a conservative republican faction in the us congress who voted this month for a huge expansion of the national debt to pay for tax cuts called himself a “ fiscal conservative ” on sunday and urged budget restraint in in keeping with a sharp pivot under way among republicans us representative mark meadows speaking on cbs ’ “ face the nation ” drew a hard line on federal spending which lawmakers are bracing to do battle over in january when they return from the holidays on wednesday lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues such as immigration policy even as the november congressional election campaigns approach in which republicans will seek to keep control of congress president donald trump and his republicans want a big budget increase in military spending while democrats also want proportional increases for nondefense “ discretionary ” spending on programs that support education scientific research infrastructure public health and environmental protection “ the trump administration has already been willing to say ‘ we ’ re going to increase nondefense discretionary spending by about percent ’ ” meadows chairman of the small but influential house freedom caucus said on the program “ now democrats are saying that ’ s not enough we need to give the government a pay raise of to percent for a fiscal conservative i don ’ t see where the rationale is eventually you run out of other people ’ s money ” he said meadows was among republicans who voted in late december for their party ’ s debtfinanced tax overhaul which is expected to balloon the federal budget deficit and add about trillion over years to the trillion national debt “ it ’ s interesting to hear mark talk about fiscal responsibility ” democratic us representative joseph crowley said on cbs crowley said the republican tax bill would require the united states to borrow trillion to be paid off by future generations to finance tax cuts for corporations and the rich “ this is one of the least fiscally responsible bills we ’ ve ever seen passed in the history of the house of representatives i think we ’ re going to be paying for this for many many years to come ” crowley said republicans insist the tax package the biggest us tax overhaul in more than years will boost the economy and job growth house speaker paul ryan who also supported the tax bill recently went further than meadows making clear in a radio interview that welfare or “ entitlement reform ” as the party often calls it would be a top republican priority in in republican parlance “ entitlement ” programs mean food stamps housing assistance medicare and medicaid health insurance for the elderly poor and disabled as well as other programs created by washington to assist the needy democrats seized on ryan ’ s early december remarks saying they showed republicans would try to pay for their tax overhaul by seeking spending cuts for social programs but the goals of house republicans may have to take a back seat to the senate where the votes of some democrats will be needed to approve a budget and prevent a government shutdown democrats will use their leverage in the senate which republicans narrowly control to defend both discretionary nondefense programs and social spending while tackling the issue of the “ dreamers ” people brought illegally to the country as children trump in september put a march expiration date on the deferred action for childhood arrivals or daca program which protects the young immigrants from deportation and provides them with work permits the president has said in recent twitter messages he wants funding for his proposed mexican border wall and other immigration law changes in exchange for agreeing to help the dreamers representative debbie dingell told cbs she did not favor linking that issue to other policy objectives such as wall funding “ we need to do daca clean ” she said on wednesday trump aides will meet with congressional leaders to discuss those issues that will be followed by a weekend of strategy sessions for trump and republican leaders on jan and the white house said trump was also scheduled to meet on sunday with florida republican governor rick scott who wants more emergency aid the house has passed an billion aid package after hurricanes in florida texas and puerto rico and wildfires in california the package far exceeded the billion requested by the trump administration the senate has not yet voted on the aid\n",
      "\n",
      "Sample text after 'Lowercase, Remove Punctuation & Stopwords' preprocessing:\n",
      "washington reuters head conservative republican faction us congress voted month huge expansion national debt pay tax cuts called “ fiscal conservative ” sunday urged budget restraint keeping sharp pivot way among republicans us representative mark meadows speaking cbs ’ “ face nation ” drew hard line federal spending lawmakers bracing battle january return holidays wednesday lawmakers begin trying pass federal budget fight likely linked issues immigration policy even november congressional election campaigns approach republicans seek keep control congress president donald trump republicans want big budget increase military spending democrats also want proportional increases nondefense “ discretionary ” spending programs support education scientific research infrastructure public health environmental protection “ trump administration already willing say ‘ ’ going increase nondefense discretionary spending percent ’ ” meadows chairman small influential house freedom caucus said program “ democrats saying ’ enough need give government pay raise percent fiscal conservative ’ see rationale eventually run people ’ money ” said meadows among republicans voted late december party ’ debtfinanced tax overhaul expected balloon federal budget deficit add trillion years trillion national debt “ ’ interesting hear mark talk fiscal responsibility ” democratic us representative joseph crowley said cbs crowley said republican tax bill would require united states borrow trillion paid future generations finance tax cuts corporations rich “ one least fiscally responsible bills ’ ever seen passed history house representatives think ’ going paying many many years come ” crowley said republicans insist tax package biggest us tax overhaul years boost economy job growth house speaker paul ryan also supported tax bill recently went meadows making clear radio interview welfare “ entitlement reform ” party often calls would top republican priority republican parlance “ entitlement ” programs mean food stamps housing assistance medicare medicaid health insurance elderly poor disabled well programs created washington assist needy democrats seized ryan ’ early december remarks saying showed republicans would try pay tax overhaul seeking spending cuts social programs goals house republicans may take back seat senate votes democrats needed approve budget prevent government shutdown democrats use leverage senate republicans narrowly control defend discretionary nondefense programs social spending tackling issue “ dreamers ” people brought illegally country children trump september put march expiration date deferred action childhood arrivals daca program protects young immigrants deportation provides work permits president said recent twitter messages wants funding proposed mexican border wall immigration law changes exchange agreeing help dreamers representative debbie dingell told cbs favor linking issue policy objectives wall funding “ need daca clean ” said wednesday trump aides meet congressional leaders discuss issues followed weekend strategy sessions trump republican leaders jan white house said trump also scheduled meet sunday florida republican governor rick scott wants emergency aid house passed billion aid package hurricanes florida texas puerto rico wildfires california package far exceeded billion requested trump administration senate yet voted aid\n",
      "\n",
      "Sample text after 'Full Preprocessing' preprocessing:\n",
      "washington reuter head conserv republican faction us congress vote month huge expans nation debt pay tax cut call “ fiscal conserv ” sunday urg budget restraint keep sharp pivot way among republican us repres mark meadow speak cb ’ “ face nation ” drew hard line feder spend lawmak brace battl januari return holiday wednesday lawmak begin tri pass feder budget fight like link issu immigr polici even novemb congression elect campaign approach republican seek keep control congress presid donald trump republican want big budget increas militari spend democrat also want proport increas nondefens “ discretionari ” spend program support educ scientif research infrastructur public health environment protect “ trump administr alreadi will say ‘ ’ go increas nondefens discretionari spend percent ’ ” meadow chairman small influenti hous freedom caucu said program “ democrat say ’ enough need give govern pay rais percent fiscal conserv ’ see rational eventu run peopl ’ money ” said meadow among republican vote late decemb parti ’ debtfinanc tax overhaul expect balloon feder budget deficit add trillion year trillion nation debt “ ’ interest hear mark talk fiscal respons ” democrat us repres joseph crowley said cb crowley said republican tax bill would requir unit state borrow trillion paid futur gener financ tax cut corpor rich “ one least fiscal respons bill ’ ever seen pass histori hous repres think ’ go pay mani mani year come ” crowley said republican insist tax packag biggest us tax overhaul year boost economi job growth hous speaker paul ryan also support tax bill recent went meadow make clear radio interview welfar “ entitl reform ” parti often call would top republican prioriti republican parlanc “ entitl ” program mean food stamp hous assist medicar medicaid health insur elderli poor disabl well program creat washington assist needi democrat seiz ryan ’ earli decemb remark say show republican would tri pay tax overhaul seek spend cut social program goal hous republican may take back seat senat vote democrat need approv budget prevent govern shutdown democrat use leverag senat republican narrowli control defend discretionari nondefens program social spend tackl issu “ dreamer ” peopl brought illeg countri children trump septemb put march expir date defer action childhood arriv daca program protect young immigr deport provid work permit presid said recent twitter messag want fund propos mexican border wall immigr law chang exchang agre help dreamer repres debbi dingel told cb favor link issu polici object wall fund “ need daca clean ” said wednesday trump aid meet congression leader discuss issu follow weekend strategi session trump republican leader jan white hous said trump also schedul meet sunday florida republican governor rick scott want emerg aid hous pass billion aid packag hurrican florida texa puerto rico wildfir california packag far exceed billion request trump administr senat yet vote aid\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Apply Different Preprocessing Steps\n",
    "# Define different preprocessing configurations\n",
    "preprocessing_steps = {\n",
    "    'Basic': {'remove_stopwords': False, 'to_lower': False, 'remove_punctuation': False},\n",
    "    'Lowercase': {'remove_stopwords': False, 'to_lower': True, 'remove_punctuation': False},\n",
    "    'Lowercase & Remove Punctuation': {'remove_stopwords': False, 'to_lower': True, 'remove_punctuation': True},\n",
    "    'Lowercase, Remove Punctuation & Stopwords': {'remove_stopwords': True, 'to_lower': True, 'remove_punctuation': True},\n",
    "    'Full Preprocessing': {'remove_stopwords': True, 'to_lower': True, 'remove_punctuation': True, 'perform_stemming': True}\n",
    "}\n",
    "\n",
    "# Create a dictionary to store processed texts\n",
    "processed_texts = {}\n",
    "\n",
    "for step, params in preprocessing_steps.items():\n",
    "    print(f\"Applying preprocessing: {step}\")\n",
    "    processed = df['text'].apply(lambda x: preprocess_text(x, \n",
    "                                                           remove_stopwords=params.get('remove_stopwords', False),\n",
    "                                                           to_lower=params.get('to_lower', False),\n",
    "                                                           remove_punctuation=params.get('remove_punctuation', False),\n",
    "                                                           perform_stemming=params.get('perform_stemming', False),\n",
    "                                                           perform_lemmatization=params.get('perform_lemmatization', False)))\n",
    "    processed_texts[step] = processed\n",
    "\n",
    "# Example: Display processed texts\n",
    "for step in preprocessing_steps.keys():\n",
    "    print(f\"\\nSample text after '{step}' preprocessing:\")\n",
    "    print(processed_texts[step].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ebf21a7-776a-4fed-bb1b-3e3d0194d51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5a9c7bf-757e-4b0f-aa9b-125814e08541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded GloVe embeddings.\n",
      "Extracted GloVe embeddings.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "def download_glove(destination_path='glove.6B.zip'):\n",
    "    url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(destination_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=128):\n",
    "            f.write(chunk)\n",
    "    print(\"Downloaded GloVe embeddings.\")\n",
    "\n",
    "def extract_glove(zip_path='glove.6B.zip', extract_to='.'):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(\"Extracted GloVe embeddings.\")\n",
    "\n",
    "# Download and extract\n",
    "download_glove()\n",
    "extract_glove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42e03c20-8dcc-4e22-9951-cd272ed0f5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec Embedding shape: (35918, 100)\n",
      "NaiveD2V Embedding shape: (35918, 100)\n",
      "One-Hot Encoding shape: (35918, 5000)\n",
      "Word2Vec Embedding shape: (35918, 100)\n",
      "Loaded 400000 word vectors from GloVe.\n",
      "GloVe Embedding shape: (35918, 100)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Feature Extraction - Embedding Methods\n",
    "# Define embedding methods\n",
    "embedding_methods = ['OneHot', 'Word2Vec', 'GloVe', 'Doc2Vec', 'NaiveD2V']\n",
    "\n",
    "# We will use the 'Full Preprocessing' for embedding\n",
    "X = processed_texts['Full Preprocessing']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Function for One-Hot Encoding\n",
    "def one_hot_encode(train_texts, test_texts, max_features=5000):\n",
    "    vectorizer = CountVectorizer(max_features=max_features)\n",
    "    X_train_enc = vectorizer.fit_transform(train_texts).toarray()\n",
    "    X_test_enc = vectorizer.transform(test_texts).toarray()\n",
    "    return X_train_enc, X_test_enc, vectorizer\n",
    "\n",
    "# Function for Word2Vec\n",
    "def word2vec_embed(train_texts, test_texts, vector_size=100, window=5, min_count=1):\n",
    "    # Tokenize\n",
    "    train_tokens = [text.split() for text in train_texts]\n",
    "    test_tokens = [text.split() for text in test_texts]\n",
    "    \n",
    "    # Train Word2Vec\n",
    "    w2v_model = Word2Vec(sentences=train_tokens, vector_size=vector_size, window=window, min_count=min_count, workers=4)\n",
    "    \n",
    "    # Function to get average Word2Vec vectors\n",
    "    def get_avg_w2v(tokens, model, vector_size):\n",
    "        vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "        if len(vectors) == 0:\n",
    "            return np.zeros(vector_size)\n",
    "        else:\n",
    "            return np.mean(vectors, axis=0)\n",
    "    \n",
    "    X_train_w2v = np.array([get_avg_w2v(tokens, w2v_model, vector_size) for tokens in train_tokens])\n",
    "    X_test_w2v = np.array([get_avg_w2v(tokens, w2v_model, vector_size) for tokens in test_tokens])\n",
    "    \n",
    "    return X_train_w2v, X_test_w2v, w2v_model\n",
    "\n",
    "# Function to load GloVe embeddings\n",
    "def load_glove_embeddings(glove_file_path, embedding_dim=100):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = ''.join(values[:-embedding_dim])\n",
    "            coefs = np.asarray(values[-embedding_dim:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f'Loaded {len(embeddings_index)} word vectors from GloVe.')\n",
    "    return embeddings_index\n",
    "\n",
    "# Function for GloVe Embedding\n",
    "def glove_embed(train_texts, test_texts, embeddings_index, embedding_dim=100):\n",
    "    # Tokenize\n",
    "    train_tokens = [text.split() for text in train_texts]\n",
    "    test_tokens = [text.split() for text in test_texts]\n",
    "    \n",
    "    # Function to get average GloVe vectors\n",
    "    def get_avg_glove(tokens, embeddings, dim):\n",
    "        vectors = [embeddings[word] for word in tokens if word in embeddings]\n",
    "        if len(vectors) == 0:\n",
    "            return np.zeros(dim)\n",
    "        else:\n",
    "            return np.mean(vectors, axis=0)\n",
    "    \n",
    "    X_train_glove = np.array([get_avg_glove(tokens, embeddings_index, embedding_dim) for tokens in train_tokens])\n",
    "    X_test_glove = np.array([get_avg_glove(tokens, embeddings_index, embedding_dim) for tokens in test_tokens])\n",
    "    \n",
    "    return X_train_glove, X_test_glove\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Function for Doc2Vec Embedding\n",
    "def doc2vec_embed(train_texts, test_texts, vector_size=100, window=5, min_count=1, epochs=20):\n",
    "    # Tag documents\n",
    "    tagged_train = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(train_texts)]\n",
    "    \n",
    "    # Initialize Doc2Vec model\n",
    "    d2v_model = Doc2Vec(vector_size=vector_size, window=window, min_count=min_count, workers=4, epochs=epochs, dm=1)  # dm=1 for Distributed Memory\n",
    "    \n",
    "    # Build vocabulary\n",
    "    d2v_model.build_vocab(tagged_train)\n",
    "    \n",
    "    # Train the model\n",
    "    d2v_model.train(tagged_train, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "    \n",
    "    # Infer vectors for training and test sets\n",
    "    X_train_d2v = np.array([d2v_model.infer_vector(text.split()) for text in train_texts])\n",
    "    X_test_d2v = np.array([d2v_model.infer_vector(text.split()) for text in test_texts])\n",
    "    \n",
    "    return X_train_d2v, X_test_d2v, d2v_model\n",
    "\n",
    "# Function for NaiveD2V Embedding (Assumed as a simplified Doc2Vec)\n",
    "def naived2v_embed(train_texts, test_texts, vector_size=100, window=5, min_count=1, epochs=20):\n",
    "    tagged_train = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(train_texts)]\n",
    "    \n",
    "    # Initialize NaiveD2V model with a different configuration (e.g., dm=0 for Distributed Bag of Words)\n",
    "    naived2v_model = Doc2Vec(vector_size=vector_size, window=window, min_count=min_count, workers=4, epochs=epochs, dm=0)  # dm=0 for DBOW\n",
    "    \n",
    "    # Build vocabulary\n",
    "    naived2v_model.build_vocab(tagged_train)\n",
    "    \n",
    "    # Train the model\n",
    "    naived2v_model.train(tagged_train, total_examples=naived2v_model.corpus_count, epochs=naived2v_model.epochs)\n",
    "    \n",
    "    # Infer vectors for training and test sets\n",
    "    X_train_naived2v = np.array([naived2v_model.infer_vector(text.split()) for text in train_texts])\n",
    "    X_test_naived2v = np.array([naived2v_model.infer_vector(text.split()) for text in test_texts])\n",
    "    \n",
    "    return X_train_naived2v, X_test_naived2v, naived2v_model\n",
    "\n",
    "# Apply Doc2Vec\n",
    "X_train_d2v, X_test_d2v, d2v_model = doc2vec_embed(X_train, X_test, vector_size=100, window=5, min_count=1, epochs=20)\n",
    "print(\"Doc2Vec Embedding shape:\", X_train_d2v.shape)\n",
    "\n",
    "# # Apply NaiveD2V\n",
    "# X_train_naived2v, X_test_naived2v, naived2v_model = naived2v_embed(X_train, X_test, vector_size=100, window=5, min_count=1, epochs=20)\n",
    "# print(\"NaiveD2V Embedding shape:\", X_train_naived2v.shape)\n",
    "\n",
    "# # Apply One-Hot Encoding\n",
    "# X_train_oh, X_test_oh, vectorizer_oh = one_hot_encode(X_train, X_test, max_features=5000)\n",
    "# print(\"One-Hot Encoding shape:\", X_train_oh.shape)\n",
    "\n",
    "# # Apply Word2Vec\n",
    "# X_train_w2v, X_test_w2v, w2v_model = word2vec_embed(X_train, X_test, vector_size=100)\n",
    "# print(\"Word2Vec Embedding shape:\", X_train_w2v.shape)\n",
    "\n",
    "# # Load GloVe embeddings\n",
    "# glove_path = 'glove.6B.100d.txt'\n",
    "# embeddings_glove = load_glove_embeddings(glove_path, embedding_dim=100)\n",
    "\n",
    "# # Apply GloVe Embedding\n",
    "# X_train_glove, X_test_glove = glove_embed(X_train, X_test, embeddings_glove, embedding_dim=100)\n",
    "# print(\"GloVe Embedding shape:\", X_train_glove.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "205c94da-5830-47cf-9c37-d17ea87fef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define Feedforward Neural Network with Variable Hidden Layers\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=[], output_size=1, dropout=0.5):\n",
    "        super(FFNN, self).__init__()\n",
    "        layers = []\n",
    "        last_size = input_size\n",
    "        for hidden in hidden_sizes:\n",
    "            layers.append(nn.Linear(last_size, hidden))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            last_size = hidden\n",
    "        layers.append(nn.Linear(last_size, output_size))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c49b24a-38b4-4074-89eb-2341b9d1082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Prepare Datasets and DataLoaders\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.X = torch.tensor(features, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels.values, dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Function to create DataLoaders\n",
    "def create_dataloaders(X_train, X_test, y_train, y_test, batch_size=64):\n",
    "    train_dataset = NewsDataset(X_train, y_train)\n",
    "    test_dataset = NewsDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63d41133-11a7-4e77-97d5-a32d5af1ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Training and Evaluation Functions\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# Early Stopping Class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif current_score < self.best_score + self.min_delta:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "\n",
    "def train_model_with_early_stopping(model, train_loader, criterion, optimizer, epochs=20, device='cpu', patience=3, metric='f1'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    history = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    early_stopping = EarlyStopping(patience=patience, min_delta=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_correct = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * X_batch.size(0)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            epoch_correct += (preds == y_batch).sum().item()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "        epoch_precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "        epoch_recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "        epoch_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "        \n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['accuracy'].append(epoch_acc)\n",
    "        history['precision'].append(epoch_precision)\n",
    "        history['recall'].append(epoch_recall)\n",
    "        history['f1'].append(epoch_f1)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.4f} - Precision: {epoch_precision:.4f} - Recall: {epoch_recall:.4f} - F1: {epoch_f1:.4f}')\n",
    "        \n",
    "        # Check early stopping\n",
    "        current_score = epoch_f1 if metric == 'f1' else epoch_acc\n",
    "        early_stopping(current_score)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_model_detailed(model, test_loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, target_names=['True', 'Fake'], zero_division=0)\n",
    "    \n",
    "    print(f'Test Accuracy: {acc:.4f}')\n",
    "    print(f'Test Precision: {precision:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n",
    "    print(f'Test F1 Score: {f1:.4f}\\n')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    \n",
    "    return acc, precision, recall, f1, cm, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "949b050a-a2fa-4947-ad0f-d341d9447efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Preprocessing Step: Basic ===\n",
      "\n",
      "--- Embedding Method: OneHot ---\n",
      "Embedding OneHot shape: (35918, 5000)\n",
      "Epoch 1/20 - Loss: 0.1198 - Acc: 0.9687 - Precision: 0.9728 - Recall: 0.9672 - F1: 0.9700\n",
      "Epoch 2/20 - Loss: 0.0403 - Acc: 0.9936 - Precision: 0.9944 - Recall: 0.9933 - F1: 0.9938\n",
      "Epoch 3/20 - Loss: 0.0241 - Acc: 0.9957 - Precision: 0.9961 - Recall: 0.9956 - F1: 0.9959\n",
      "Epoch 4/20 - Loss: 0.0322 - Acc: 0.9951 - Precision: 0.9958 - Recall: 0.9949 - F1: 0.9953\n",
      "Epoch 5/20 - Loss: 0.0243 - Acc: 0.9967 - Precision: 0.9965 - Recall: 0.9972 - F1: 0.9968\n",
      "Epoch 6/20 - Loss: 0.0170 - Acc: 0.9981 - Precision: 0.9982 - Recall: 0.9981 - F1: 0.9982\n",
      "Epoch 7/20 - Loss: 0.0179 - Acc: 0.9980 - Precision: 0.9981 - Recall: 0.9981 - F1: 0.9981\n",
      "Epoch 8/20 - Loss: 0.0150 - Acc: 0.9981 - Precision: 0.9979 - Recall: 0.9984 - F1: 0.9982\n",
      "Epoch 9/20 - Loss: 0.0143 - Acc: 0.9985 - Precision: 0.9985 - Recall: 0.9987 - F1: 0.9986\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9961\n",
      "Test Precision: 0.9977\n",
      "Test Recall: 0.9949\n",
      "Test F1 Score: 0.9963\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      1.00      1.00      4284\n",
      "        Fake       1.00      0.99      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4273   11]\n",
      " [  24 4672]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Embedding Method: Word2Vec ---\n",
      "Embedding Word2Vec shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.1028 - Acc: 0.9664 - Precision: 0.9729 - Recall: 0.9625 - F1: 0.9677\n",
      "Epoch 2/20 - Loss: 0.0342 - Acc: 0.9886 - Precision: 0.9903 - Recall: 0.9880 - F1: 0.9891\n",
      "Epoch 3/20 - Loss: 0.0272 - Acc: 0.9911 - Precision: 0.9923 - Recall: 0.9907 - F1: 0.9915\n",
      "Epoch 4/20 - Loss: 0.0240 - Acc: 0.9918 - Precision: 0.9932 - Recall: 0.9911 - F1: 0.9922\n",
      "Epoch 5/20 - Loss: 0.0247 - Acc: 0.9914 - Precision: 0.9921 - Recall: 0.9914 - F1: 0.9918\n",
      "Epoch 6/20 - Loss: 0.0227 - Acc: 0.9921 - Precision: 0.9932 - Recall: 0.9917 - F1: 0.9925\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9923\n",
      "Test Precision: 0.9996\n",
      "Test Recall: 0.9857\n",
      "Test F1 Score: 0.9926\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.98      1.00      0.99      4284\n",
      "        Fake       1.00      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4282    2]\n",
      " [  67 4629]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Embedding Method: GloVe ---\n",
      "Embedding GloVe shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.3053 - Acc: 0.8699 - Precision: 0.8715 - Recall: 0.8811 - F1: 0.8763\n",
      "Epoch 2/20 - Loss: 0.1624 - Acc: 0.9398 - Precision: 0.9470 - Recall: 0.9373 - F1: 0.9421\n",
      "Epoch 3/20 - Loss: 0.1456 - Acc: 0.9464 - Precision: 0.9538 - Recall: 0.9432 - F1: 0.9485\n",
      "Epoch 4/20 - Loss: 0.1297 - Acc: 0.9520 - Precision: 0.9588 - Recall: 0.9491 - F1: 0.9539\n",
      "Epoch 5/20 - Loss: 0.1288 - Acc: 0.9540 - Precision: 0.9615 - Recall: 0.9501 - F1: 0.9558\n",
      "Epoch 6/20 - Loss: 0.1225 - Acc: 0.9567 - Precision: 0.9626 - Recall: 0.9544 - F1: 0.9585\n",
      "Epoch 7/20 - Loss: 0.1181 - Acc: 0.9569 - Precision: 0.9634 - Recall: 0.9538 - F1: 0.9586\n",
      "Epoch 8/20 - Loss: 0.1118 - Acc: 0.9594 - Precision: 0.9654 - Recall: 0.9567 - F1: 0.9610\n",
      "Epoch 9/20 - Loss: 0.1184 - Acc: 0.9592 - Precision: 0.9659 - Recall: 0.9557 - F1: 0.9608\n",
      "Epoch 10/20 - Loss: 0.1113 - Acc: 0.9603 - Precision: 0.9662 - Recall: 0.9576 - F1: 0.9619\n",
      "Epoch 11/20 - Loss: 0.1084 - Acc: 0.9617 - Precision: 0.9681 - Recall: 0.9583 - F1: 0.9632\n",
      "Epoch 12/20 - Loss: 0.1093 - Acc: 0.9613 - Precision: 0.9675 - Recall: 0.9583 - F1: 0.9629\n",
      "Epoch 13/20 - Loss: 0.1058 - Acc: 0.9614 - Precision: 0.9672 - Recall: 0.9586 - F1: 0.9629\n",
      "Epoch 14/20 - Loss: 0.1027 - Acc: 0.9627 - Precision: 0.9671 - Recall: 0.9614 - F1: 0.9643\n",
      "Epoch 15/20 - Loss: 0.1040 - Acc: 0.9636 - Precision: 0.9675 - Recall: 0.9628 - F1: 0.9652\n",
      "Epoch 16/20 - Loss: 0.1016 - Acc: 0.9644 - Precision: 0.9687 - Recall: 0.9631 - F1: 0.9659\n",
      "Epoch 17/20 - Loss: 0.1013 - Acc: 0.9636 - Precision: 0.9680 - Recall: 0.9622 - F1: 0.9651\n",
      "Epoch 18/20 - Loss: 0.1033 - Acc: 0.9646 - Precision: 0.9700 - Recall: 0.9619 - F1: 0.9660\n",
      "Epoch 19/20 - Loss: 0.0986 - Acc: 0.9653 - Precision: 0.9695 - Recall: 0.9641 - F1: 0.9668\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9708\n",
      "Test Precision: 0.9550\n",
      "Test Recall: 0.9908\n",
      "Test F1 Score: 0.9726\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      0.95      0.97      4284\n",
      "        Fake       0.96      0.99      0.97      4696\n",
      "\n",
      "    accuracy                           0.97      8980\n",
      "   macro avg       0.97      0.97      0.97      8980\n",
      "weighted avg       0.97      0.97      0.97      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4065  219]\n",
      " [  43 4653]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Embedding Method: Doc2Vec ---\n",
      "Embedding Doc2Vec shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.1007 - Acc: 0.9681 - Precision: 0.9708 - Recall: 0.9683 - F1: 0.9695\n",
      "Epoch 2/20 - Loss: 0.0561 - Acc: 0.9810 - Precision: 0.9834 - Recall: 0.9803 - F1: 0.9818\n",
      "Epoch 3/20 - Loss: 0.0458 - Acc: 0.9844 - Precision: 0.9860 - Recall: 0.9841 - F1: 0.9851\n",
      "Epoch 4/20 - Loss: 0.0427 - Acc: 0.9854 - Precision: 0.9864 - Recall: 0.9856 - F1: 0.9860\n",
      "Epoch 5/20 - Loss: 0.0371 - Acc: 0.9873 - Precision: 0.9887 - Recall: 0.9870 - F1: 0.9879\n",
      "Epoch 6/20 - Loss: 0.0348 - Acc: 0.9882 - Precision: 0.9891 - Recall: 0.9883 - F1: 0.9887\n",
      "Epoch 7/20 - Loss: 0.0335 - Acc: 0.9880 - Precision: 0.9885 - Recall: 0.9886 - F1: 0.9885\n",
      "Epoch 8/20 - Loss: 0.0304 - Acc: 0.9893 - Precision: 0.9902 - Recall: 0.9894 - F1: 0.9898\n",
      "Epoch 9/20 - Loss: 0.0277 - Acc: 0.9910 - Precision: 0.9918 - Recall: 0.9910 - F1: 0.9914\n",
      "Epoch 10/20 - Loss: 0.0284 - Acc: 0.9903 - Precision: 0.9911 - Recall: 0.9903 - F1: 0.9907\n",
      "Epoch 11/20 - Loss: 0.0260 - Acc: 0.9913 - Precision: 0.9922 - Recall: 0.9911 - F1: 0.9916\n",
      "Epoch 12/20 - Loss: 0.0257 - Acc: 0.9914 - Precision: 0.9922 - Recall: 0.9914 - F1: 0.9918\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9898\n",
      "Test Precision: 0.9863\n",
      "Test Recall: 0.9943\n",
      "Test F1 Score: 0.9902\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      0.98      0.99      4284\n",
      "        Fake       0.99      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4219   65]\n",
      " [  27 4669]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Embedding Method: NaiveD2V ---\n",
      "Embedding NaiveD2V shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.0695 - Acc: 0.9751 - Precision: 0.9646 - Recall: 0.9888 - F1: 0.9765\n",
      "Epoch 2/20 - Loss: 0.0109 - Acc: 0.9971 - Precision: 0.9974 - Recall: 0.9970 - F1: 0.9972\n",
      "Epoch 3/20 - Loss: 0.0078 - Acc: 0.9977 - Precision: 0.9980 - Recall: 0.9975 - F1: 0.9978\n",
      "Epoch 4/20 - Loss: 0.0062 - Acc: 0.9982 - Precision: 0.9984 - Recall: 0.9982 - F1: 0.9983\n",
      "Epoch 5/20 - Loss: 0.0052 - Acc: 0.9986 - Precision: 0.9988 - Recall: 0.9985 - F1: 0.9986\n",
      "Epoch 6/20 - Loss: 0.0039 - Acc: 0.9987 - Precision: 0.9989 - Recall: 0.9987 - F1: 0.9988\n",
      "Epoch 7/20 - Loss: 0.0033 - Acc: 0.9990 - Precision: 0.9990 - Recall: 0.9990 - F1: 0.9990\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9988\n",
      "Test Precision: 0.9991\n",
      "Test Recall: 0.9985\n",
      "Test F1 Score: 0.9988\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4280    4]\n",
      " [   7 4689]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Preprocessing Step: Lowercase ===\n",
      "\n",
      "--- Embedding Method: OneHot ---\n",
      "Embedding OneHot shape: (35918, 5000)\n",
      "Epoch 1/20 - Loss: 0.1113 - Acc: 0.9705 - Precision: 0.9739 - Recall: 0.9695 - F1: 0.9717\n",
      "Epoch 2/20 - Loss: 0.0364 - Acc: 0.9935 - Precision: 0.9946 - Recall: 0.9930 - F1: 0.9938\n",
      "Epoch 3/20 - Loss: 0.0248 - Acc: 0.9951 - Precision: 0.9956 - Recall: 0.9950 - F1: 0.9953\n",
      "Epoch 4/20 - Loss: 0.0242 - Acc: 0.9956 - Precision: 0.9958 - Recall: 0.9957 - F1: 0.9958\n",
      "Epoch 5/20 - Loss: 0.0212 - Acc: 0.9969 - Precision: 0.9971 - Recall: 0.9970 - F1: 0.9971\n",
      "Epoch 6/20 - Loss: 0.0115 - Acc: 0.9977 - Precision: 0.9981 - Recall: 0.9975 - F1: 0.9978\n",
      "Epoch 7/20 - Loss: 0.0078 - Acc: 0.9987 - Precision: 0.9991 - Recall: 0.9985 - F1: 0.9988\n",
      "Epoch 8/20 - Loss: 0.0160 - Acc: 0.9972 - Precision: 0.9977 - Recall: 0.9970 - F1: 0.9974\n",
      "Epoch 9/20 - Loss: 0.0119 - Acc: 0.9978 - Precision: 0.9982 - Recall: 0.9976 - F1: 0.9979\n",
      "Epoch 10/20 - Loss: 0.0095 - Acc: 0.9986 - Precision: 0.9986 - Recall: 0.9987 - F1: 0.9986\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9955\n",
      "Test Precision: 0.9972\n",
      "Test Recall: 0.9943\n",
      "Test F1 Score: 0.9957\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      1.00      1.00      4284\n",
      "        Fake       1.00      0.99      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4271   13]\n",
      " [  27 4669]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Embedding Method: Word2Vec ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m         X_train_emb, X_test_emb \u001b[38;5;241m=\u001b[39m glove_embed(X_train, X_test, embeddings_glove, embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;66;03m# Handle potential issues if 'GloVe' embeddings are not loaded\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m         X_train_emb, X_test_emb, _ \u001b[38;5;241m=\u001b[39m apply_embedding(embed_method, processed_texts, X_train, X_test)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed with error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[66], line 11\u001b[0m, in \u001b[0;36mapply_embedding\u001b[1;34m(method, processed_texts, train_texts, test_texts)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m one_hot_encode(train_texts, test_texts, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWord2Vec\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word2vec_embed(train_texts, test_texts, vector_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGloVe\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m glove_embed(train_texts, test_texts, embeddings_glove, embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[52], line 36\u001b[0m, in \u001b[0;36mword2vec_embed\u001b[1;34m(train_texts, test_texts, vector_size, window, min_count)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(vectors, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m X_train_w2v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_avg_w2v(tokens, w2v_model, vector_size) \u001b[38;5;28;01mfor\u001b[39;00m tokens \u001b[38;5;129;01min\u001b[39;00m train_tokens])\n\u001b[0;32m     37\u001b[0m X_test_w2v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_avg_w2v(tokens, w2v_model, vector_size) \u001b[38;5;28;01mfor\u001b[39;00m tokens \u001b[38;5;129;01min\u001b[39;00m test_tokens])\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_train_w2v, X_test_w2v, w2v_model\n",
      "Cell \u001b[1;32mIn[52], line 34\u001b[0m, in \u001b[0;36mword2vec_embed.<locals>.get_avg_w2v\u001b[1;34m(tokens, model, vector_size)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(vector_size)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(vectors, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3505\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 102\u001b[0m     arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[0;32m    104\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 10: Train and Evaluate All Preprocessing-Embedding Combinations\n",
    "\n",
    "# Define embedding methods\n",
    "embedding_methods = ['OneHot', 'Word2Vec', 'GloVe', 'Doc2Vec', 'NaiveD2V']\n",
    "\n",
    "# Function to apply embeddings based on method\n",
    "def apply_embedding(method, processed_texts, train_texts, test_texts):\n",
    "    if method == 'OneHot':\n",
    "        return one_hot_encode(train_texts, test_texts, max_features=5000)\n",
    "    elif method == 'Word2Vec':\n",
    "        return word2vec_embed(train_texts, test_texts, vector_size=100)\n",
    "    elif method == 'GloVe':\n",
    "        return glove_embed(train_texts, test_texts, embeddings_glove, embedding_dim=100)\n",
    "    elif method == 'Doc2Vec':\n",
    "        return doc2vec_embed(train_texts, test_texts, vector_size=100, window=5, min_count=1, epochs=20)\n",
    "    elif method == 'NaiveD2V':\n",
    "        return naived2v_embed(train_texts, test_texts, vector_size=100, window=5, min_count=1, epochs=20)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported embedding method.\")\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "# Iterate over each preprocessing step\n",
    "for prep_name, processed_texts in processed_texts.items():\n",
    "    print(f\"=== Preprocessing Step: {prep_name} ===\")\n",
    "    \n",
    "    # Prepare features and labels\n",
    "    X = processed_texts\n",
    "    y = df['label']\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Iterate over each embedding method\n",
    "    for embed_method in embedding_methods:\n",
    "        print(f\"\\n--- Embedding Method: {embed_method} ---\")\n",
    "        \n",
    "        # Apply embedding\n",
    "        try:\n",
    "            if embed_method == 'GloVe':\n",
    "                X_train_emb, X_test_emb = glove_embed(X_train, X_test, embeddings_glove, embedding_dim=100)\n",
    "                # Handle potential issues if 'GloVe' embeddings are not loaded\n",
    "            else:\n",
    "                X_train_emb, X_test_emb, _ = apply_embedding(embed_method, processed_texts, X_train, X_test)\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding {embed_method} failed with error: {e}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Embedding {embed_method} shape: {X_train_emb.shape}\")\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_loader, test_loader = create_dataloaders(X_train_emb, X_test_emb, y_train, y_test, batch_size=64)\n",
    "        \n",
    "        # Define model architecture\n",
    "        input_size = X_train_emb.shape[1]\n",
    "        hidden_sizes = [128, 64]  # Default hidden layers; can be adjusted\n",
    "        model = FFNN(input_size=input_size, hidden_sizes=hidden_sizes, dropout=0.5)\n",
    "        \n",
    "        # Define loss and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        history = train_model_with_early_stopping(\n",
    "            model, train_loader, criterion, optimizer,\n",
    "            epochs=20, device=device, patience=3, metric='f1'\n",
    "        )\n",
    "        \n",
    "        # Evaluate the model\n",
    "        print(\"\\nEvaluation on Test Set:\")\n",
    "        acc, precision, recall, f1, cm, report = evaluate_model_detailed(model, test_loader, device)\n",
    "        \n",
    "        # Store the results\n",
    "        key = f\"{prep_name} + {embed_method}\"\n",
    "        results[key] = {\n",
    "            'Accuracy': acc,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'Confusion Matrix': cm,\n",
    "            'Classification Report': report,\n",
    "            'Training History': history\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Display a summary of results\n",
    "summary = pd.DataFrame({\n",
    "    'Combination': list(results.keys()),\n",
    "    'Accuracy': [v['Accuracy'] for v in results.values()],\n",
    "    'Precision': [v['Precision'] for v in results.values()],\n",
    "    'Recall': [v['Recall'] for v in results.values()],\n",
    "    'F1 Score': [v['F1 Score'] for v in results.values()]\n",
    "})\n",
    "\n",
    "print(\"=== Summary of All Preprocessing-Embedding Combinations ===\")\n",
    "display(summary.sort_values(by='F1 Score', ascending=False).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "740e3e31-2f51-4277-bc18-c88b063cef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Embedding Method: OneHot ===\n",
      "\n",
      "--- Preprocessing Step: Lowercase ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding OneHot with 'Lowercase' shape: (35918, 5000)\n",
      "Epoch 1/20 - Loss: 0.1196 - Acc: 0.9675 - Precision: 0.9759 - Recall: 0.9616 - F1: 0.9687\n",
      "Epoch 2/20 - Loss: 0.0475 - Acc: 0.9928 - Precision: 0.9934 - Recall: 0.9928 - F1: 0.9931\n",
      "Epoch 3/20 - Loss: 0.0301 - Acc: 0.9945 - Precision: 0.9950 - Recall: 0.9945 - F1: 0.9948\n",
      "Epoch 4/20 - Loss: 0.0276 - Acc: 0.9970 - Precision: 0.9971 - Recall: 0.9972 - F1: 0.9972\n",
      "Epoch 5/20 - Loss: 0.0247 - Acc: 0.9972 - Precision: 0.9974 - Recall: 0.9972 - F1: 0.9973\n",
      "Epoch 6/20 - Loss: 0.0200 - Acc: 0.9975 - Precision: 0.9977 - Recall: 0.9976 - F1: 0.9976\n",
      "Epoch 7/20 - Loss: 0.0171 - Acc: 0.9983 - Precision: 0.9983 - Recall: 0.9984 - F1: 0.9983\n",
      "Epoch 8/20 - Loss: 0.0181 - Acc: 0.9973 - Precision: 0.9976 - Recall: 0.9972 - F1: 0.9974\n",
      "Epoch 9/20 - Loss: 0.0138 - Acc: 0.9980 - Precision: 0.9984 - Recall: 0.9977 - F1: 0.9981\n",
      "Epoch 10/20 - Loss: 0.0097 - Acc: 0.9989 - Precision: 0.9988 - Recall: 0.9992 - F1: 0.9990\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9958\n",
      "Test Precision: 0.9983\n",
      "Test Recall: 0.9936\n",
      "Test F1 Score: 0.9959\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      1.00      1.00      4284\n",
      "        Fake       1.00      0.99      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4276    8]\n",
      " [  30 4666]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Preprocessing Step: Lowercase & Remove Punctuation ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding OneHot with 'Lowercase & Remove Punctuation' shape: (35918, 5000)\n",
      "Epoch 1/20 - Loss: 0.1215 - Acc: 0.9711 - Precision: 0.9720 - Recall: 0.9727 - F1: 0.9724\n",
      "Epoch 2/20 - Loss: 0.0398 - Acc: 0.9930 - Precision: 0.9936 - Recall: 0.9929 - F1: 0.9933\n",
      "Epoch 3/20 - Loss: 0.0269 - Acc: 0.9953 - Precision: 0.9955 - Recall: 0.9955 - F1: 0.9955\n",
      "Epoch 4/20 - Loss: 0.0229 - Acc: 0.9962 - Precision: 0.9963 - Recall: 0.9964 - F1: 0.9963\n",
      "Epoch 5/20 - Loss: 0.0164 - Acc: 0.9972 - Precision: 0.9972 - Recall: 0.9974 - F1: 0.9973\n",
      "Epoch 6/20 - Loss: 0.0157 - Acc: 0.9978 - Precision: 0.9977 - Recall: 0.9980 - F1: 0.9979\n",
      "Epoch 7/20 - Loss: 0.0160 - Acc: 0.9977 - Precision: 0.9979 - Recall: 0.9977 - F1: 0.9978\n",
      "Epoch 8/20 - Loss: 0.0150 - Acc: 0.9978 - Precision: 0.9980 - Recall: 0.9977 - F1: 0.9979\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9944\n",
      "Test Precision: 0.9947\n",
      "Test Recall: 0.9947\n",
      "Test F1 Score: 0.9947\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      0.99      0.99      4284\n",
      "        Fake       0.99      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4259   25]\n",
      " [  25 4671]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Embedding Method: Word2Vec ===\n",
      "\n",
      "--- Preprocessing Step: Lowercase & Remove Punctuation ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding Word2Vec with 'Lowercase & Remove Punctuation' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.1343 - Acc: 0.9526 - Precision: 0.9677 - Recall: 0.9407 - F1: 0.9540\n",
      "Epoch 2/20 - Loss: 0.0671 - Acc: 0.9773 - Precision: 0.9789 - Recall: 0.9775 - F1: 0.9782\n",
      "Epoch 3/20 - Loss: 0.0574 - Acc: 0.9804 - Precision: 0.9823 - Recall: 0.9801 - F1: 0.9812\n",
      "Epoch 4/20 - Loss: 0.0534 - Acc: 0.9818 - Precision: 0.9839 - Recall: 0.9813 - F1: 0.9826\n",
      "Epoch 5/20 - Loss: 0.0494 - Acc: 0.9828 - Precision: 0.9852 - Recall: 0.9820 - F1: 0.9836\n",
      "Epoch 6/20 - Loss: 0.0481 - Acc: 0.9838 - Precision: 0.9863 - Recall: 0.9827 - F1: 0.9845\n",
      "Epoch 7/20 - Loss: 0.0458 - Acc: 0.9848 - Precision: 0.9871 - Recall: 0.9838 - F1: 0.9854\n",
      "Epoch 8/20 - Loss: 0.0450 - Acc: 0.9845 - Precision: 0.9868 - Recall: 0.9836 - F1: 0.9852\n",
      "Epoch 9/20 - Loss: 0.0445 - Acc: 0.9849 - Precision: 0.9876 - Recall: 0.9833 - F1: 0.9855\n",
      "Epoch 10/20 - Loss: 0.0428 - Acc: 0.9859 - Precision: 0.9886 - Recall: 0.9845 - F1: 0.9865\n",
      "Epoch 11/20 - Loss: 0.0406 - Acc: 0.9869 - Precision: 0.9897 - Recall: 0.9851 - F1: 0.9874\n",
      "Epoch 12/20 - Loss: 0.0408 - Acc: 0.9862 - Precision: 0.9890 - Recall: 0.9845 - F1: 0.9867\n",
      "Epoch 13/20 - Loss: 0.0396 - Acc: 0.9870 - Precision: 0.9894 - Recall: 0.9856 - F1: 0.9875\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9879\n",
      "Test Precision: 0.9856\n",
      "Test Recall: 0.9913\n",
      "Test F1 Score: 0.9884\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      0.98      0.99      4284\n",
      "        Fake       0.99      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4216   68]\n",
      " [  41 4655]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Preprocessing Step: Lowercase, Remove Punctuation & Stopwords ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding Word2Vec with 'Lowercase, Remove Punctuation & Stopwords' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.1139 - Acc: 0.9622 - Precision: 0.9603 - Recall: 0.9677 - F1: 0.9640\n",
      "Epoch 2/20 - Loss: 0.0530 - Acc: 0.9827 - Precision: 0.9842 - Recall: 0.9828 - F1: 0.9835\n",
      "Epoch 3/20 - Loss: 0.0437 - Acc: 0.9853 - Precision: 0.9868 - Recall: 0.9851 - F1: 0.9860\n",
      "Epoch 4/20 - Loss: 0.0398 - Acc: 0.9867 - Precision: 0.9880 - Recall: 0.9865 - F1: 0.9873\n",
      "Epoch 5/20 - Loss: 0.0375 - Acc: 0.9877 - Precision: 0.9893 - Recall: 0.9871 - F1: 0.9882\n",
      "Epoch 6/20 - Loss: 0.0342 - Acc: 0.9886 - Precision: 0.9901 - Recall: 0.9880 - F1: 0.9890\n",
      "Epoch 7/20 - Loss: 0.0331 - Acc: 0.9887 - Precision: 0.9901 - Recall: 0.9883 - F1: 0.9892\n",
      "Epoch 8/20 - Loss: 0.0315 - Acc: 0.9897 - Precision: 0.9909 - Recall: 0.9895 - F1: 0.9902\n",
      "Epoch 9/20 - Loss: 0.0317 - Acc: 0.9898 - Precision: 0.9910 - Recall: 0.9894 - F1: 0.9902\n",
      "Epoch 10/20 - Loss: 0.0292 - Acc: 0.9905 - Precision: 0.9919 - Recall: 0.9898 - F1: 0.9909\n",
      "Epoch 11/20 - Loss: 0.0293 - Acc: 0.9898 - Precision: 0.9911 - Recall: 0.9894 - F1: 0.9902\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9901\n",
      "Test Precision: 0.9942\n",
      "Test Recall: 0.9868\n",
      "Test F1 Score: 0.9905\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      0.99      0.99      4284\n",
      "        Fake       0.99      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4257   27]\n",
      " [  62 4634]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Preprocessing Step: Full Preprocessing ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding Word2Vec with 'Full Preprocessing' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.1262 - Acc: 0.9553 - Precision: 0.9709 - Recall: 0.9429 - F1: 0.9567\n",
      "Epoch 2/20 - Loss: 0.0602 - Acc: 0.9797 - Precision: 0.9818 - Recall: 0.9794 - F1: 0.9806\n",
      "Epoch 3/20 - Loss: 0.0523 - Acc: 0.9819 - Precision: 0.9836 - Recall: 0.9817 - F1: 0.9827\n",
      "Epoch 4/20 - Loss: 0.0473 - Acc: 0.9837 - Precision: 0.9854 - Recall: 0.9833 - F1: 0.9844\n",
      "Epoch 5/20 - Loss: 0.0440 - Acc: 0.9848 - Precision: 0.9873 - Recall: 0.9836 - F1: 0.9854\n",
      "Epoch 6/20 - Loss: 0.0430 - Acc: 0.9851 - Precision: 0.9877 - Recall: 0.9838 - F1: 0.9857\n",
      "Epoch 7/20 - Loss: 0.0403 - Acc: 0.9857 - Precision: 0.9882 - Recall: 0.9845 - F1: 0.9863\n",
      "Epoch 8/20 - Loss: 0.0385 - Acc: 0.9875 - Precision: 0.9891 - Recall: 0.9870 - F1: 0.9880\n",
      "Epoch 9/20 - Loss: 0.0369 - Acc: 0.9879 - Precision: 0.9894 - Recall: 0.9874 - F1: 0.9884\n",
      "Epoch 10/20 - Loss: 0.0364 - Acc: 0.9875 - Precision: 0.9900 - Recall: 0.9861 - F1: 0.9880\n",
      "Epoch 11/20 - Loss: 0.0340 - Acc: 0.9884 - Precision: 0.9898 - Recall: 0.9881 - F1: 0.9889\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9885\n",
      "Test Precision: 0.9875\n",
      "Test Recall: 0.9906\n",
      "Test F1 Score: 0.9891\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      0.99      0.99      4284\n",
      "        Fake       0.99      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4225   59]\n",
      " [  44 4652]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Embedding Method: GloVe ===\n",
      "\n",
      "--- Preprocessing Step: Lowercase & Remove Punctuation ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding GloVe with 'Lowercase & Remove Punctuation' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.2933 - Acc: 0.8810 - Precision: 0.8877 - Recall: 0.8844 - F1: 0.8861\n",
      "Epoch 2/20 - Loss: 0.1767 - Acc: 0.9342 - Precision: 0.9423 - Recall: 0.9311 - F1: 0.9367\n",
      "Epoch 3/20 - Loss: 0.1600 - Acc: 0.9419 - Precision: 0.9515 - Recall: 0.9367 - F1: 0.9440\n",
      "Epoch 4/20 - Loss: 0.1540 - Acc: 0.9441 - Precision: 0.9526 - Recall: 0.9399 - F1: 0.9462\n",
      "Epoch 5/20 - Loss: 0.1483 - Acc: 0.9457 - Precision: 0.9553 - Recall: 0.9402 - F1: 0.9477\n",
      "Epoch 6/20 - Loss: 0.1438 - Acc: 0.9487 - Precision: 0.9562 - Recall: 0.9453 - F1: 0.9507\n",
      "Epoch 7/20 - Loss: 0.1366 - Acc: 0.9504 - Precision: 0.9584 - Recall: 0.9461 - F1: 0.9522\n",
      "Epoch 8/20 - Loss: 0.1314 - Acc: 0.9528 - Precision: 0.9606 - Recall: 0.9486 - F1: 0.9546\n",
      "Epoch 9/20 - Loss: 0.1287 - Acc: 0.9539 - Precision: 0.9616 - Recall: 0.9497 - F1: 0.9556\n",
      "Epoch 10/20 - Loss: 0.1262 - Acc: 0.9538 - Precision: 0.9617 - Recall: 0.9494 - F1: 0.9555\n",
      "Epoch 11/20 - Loss: 0.1264 - Acc: 0.9550 - Precision: 0.9613 - Recall: 0.9523 - F1: 0.9568\n",
      "Epoch 12/20 - Loss: 0.1236 - Acc: 0.9570 - Precision: 0.9638 - Recall: 0.9535 - F1: 0.9587\n",
      "Epoch 13/20 - Loss: 0.1195 - Acc: 0.9569 - Precision: 0.9633 - Recall: 0.9539 - F1: 0.9586\n",
      "Epoch 14/20 - Loss: 0.1210 - Acc: 0.9571 - Precision: 0.9636 - Recall: 0.9540 - F1: 0.9588\n",
      "Epoch 15/20 - Loss: 0.1157 - Acc: 0.9584 - Precision: 0.9652 - Recall: 0.9549 - F1: 0.9600\n",
      "Epoch 16/20 - Loss: 0.1120 - Acc: 0.9592 - Precision: 0.9647 - Recall: 0.9570 - F1: 0.9608\n",
      "Epoch 17/20 - Loss: 0.1168 - Acc: 0.9576 - Precision: 0.9632 - Recall: 0.9553 - F1: 0.9593\n",
      "Epoch 18/20 - Loss: 0.1108 - Acc: 0.9607 - Precision: 0.9658 - Recall: 0.9587 - F1: 0.9623\n",
      "Epoch 19/20 - Loss: 0.1090 - Acc: 0.9603 - Precision: 0.9662 - Recall: 0.9576 - F1: 0.9619\n",
      "Epoch 20/20 - Loss: 0.1070 - Acc: 0.9632 - Precision: 0.9682 - Recall: 0.9612 - F1: 0.9647\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9707\n",
      "Test Precision: 0.9689\n",
      "Test Recall: 0.9753\n",
      "Test F1 Score: 0.9721\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.97      0.97      0.97      4284\n",
      "        Fake       0.97      0.98      0.97      4696\n",
      "\n",
      "    accuracy                           0.97      8980\n",
      "   macro avg       0.97      0.97      0.97      8980\n",
      "weighted avg       0.97      0.97      0.97      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4137  147]\n",
      " [ 116 4580]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Preprocessing Step: Lowercase, Remove Punctuation & Stopwords ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding GloVe with 'Lowercase, Remove Punctuation & Stopwords' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.2565 - Acc: 0.8973 - Precision: 0.9003 - Recall: 0.9036 - F1: 0.9020\n",
      "Epoch 2/20 - Loss: 0.1539 - Acc: 0.9435 - Precision: 0.9522 - Recall: 0.9392 - F1: 0.9456\n",
      "Epoch 3/20 - Loss: 0.1349 - Acc: 0.9502 - Precision: 0.9583 - Recall: 0.9460 - F1: 0.9521\n",
      "Epoch 4/20 - Loss: 0.1239 - Acc: 0.9560 - Precision: 0.9623 - Recall: 0.9531 - F1: 0.9577\n",
      "Epoch 5/20 - Loss: 0.1170 - Acc: 0.9570 - Precision: 0.9631 - Recall: 0.9543 - F1: 0.9587\n",
      "Epoch 6/20 - Loss: 0.1115 - Acc: 0.9605 - Precision: 0.9662 - Recall: 0.9581 - F1: 0.9621\n",
      "Epoch 7/20 - Loss: 0.1065 - Acc: 0.9614 - Precision: 0.9668 - Recall: 0.9590 - F1: 0.9629\n",
      "Epoch 8/20 - Loss: 0.1012 - Acc: 0.9639 - Precision: 0.9681 - Recall: 0.9626 - F1: 0.9654\n",
      "Epoch 9/20 - Loss: 0.1009 - Acc: 0.9644 - Precision: 0.9692 - Recall: 0.9625 - F1: 0.9659\n",
      "Epoch 10/20 - Loss: 0.0987 - Acc: 0.9660 - Precision: 0.9712 - Recall: 0.9636 - F1: 0.9674\n",
      "Epoch 11/20 - Loss: 0.0946 - Acc: 0.9669 - Precision: 0.9706 - Recall: 0.9660 - F1: 0.9683\n",
      "Epoch 12/20 - Loss: 0.0919 - Acc: 0.9671 - Precision: 0.9706 - Recall: 0.9663 - F1: 0.9684\n",
      "Epoch 13/20 - Loss: 0.0924 - Acc: 0.9677 - Precision: 0.9712 - Recall: 0.9668 - F1: 0.9690\n",
      "Epoch 14/20 - Loss: 0.0899 - Acc: 0.9684 - Precision: 0.9722 - Recall: 0.9673 - F1: 0.9697\n",
      "Epoch 15/20 - Loss: 0.0845 - Acc: 0.9702 - Precision: 0.9729 - Recall: 0.9700 - F1: 0.9715\n",
      "Epoch 16/20 - Loss: 0.0846 - Acc: 0.9714 - Precision: 0.9747 - Recall: 0.9706 - F1: 0.9726\n",
      "Epoch 17/20 - Loss: 0.0858 - Acc: 0.9702 - Precision: 0.9730 - Recall: 0.9699 - F1: 0.9714\n",
      "Epoch 18/20 - Loss: 0.0818 - Acc: 0.9703 - Precision: 0.9737 - Recall: 0.9694 - F1: 0.9716\n",
      "Epoch 19/20 - Loss: 0.0786 - Acc: 0.9717 - Precision: 0.9741 - Recall: 0.9717 - F1: 0.9729\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9791\n",
      "Test Precision: 0.9847\n",
      "Test Recall: 0.9751\n",
      "Test F1 Score: 0.9799\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.97      0.98      0.98      4284\n",
      "        Fake       0.98      0.98      0.98      4696\n",
      "\n",
      "    accuracy                           0.98      8980\n",
      "   macro avg       0.98      0.98      0.98      8980\n",
      "weighted avg       0.98      0.98      0.98      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4213   71]\n",
      " [ 117 4579]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Preprocessing Step: Full Preprocessing ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding GloVe with 'Full Preprocessing' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.2520 - Acc: 0.8987 - Precision: 0.9248 - Recall: 0.8777 - F1: 0.9006\n",
      "Epoch 2/20 - Loss: 0.1586 - Acc: 0.9416 - Precision: 0.9510 - Recall: 0.9365 - F1: 0.9437\n",
      "Epoch 3/20 - Loss: 0.1400 - Acc: 0.9481 - Precision: 0.9555 - Recall: 0.9448 - F1: 0.9501\n",
      "Epoch 4/20 - Loss: 0.1312 - Acc: 0.9533 - Precision: 0.9592 - Recall: 0.9512 - F1: 0.9552\n",
      "Epoch 5/20 - Loss: 0.1209 - Acc: 0.9568 - Precision: 0.9622 - Recall: 0.9549 - F1: 0.9585\n",
      "Epoch 6/20 - Loss: 0.1164 - Acc: 0.9581 - Precision: 0.9629 - Recall: 0.9567 - F1: 0.9598\n",
      "Epoch 7/20 - Loss: 0.1125 - Acc: 0.9587 - Precision: 0.9636 - Recall: 0.9573 - F1: 0.9604\n",
      "Epoch 8/20 - Loss: 0.1088 - Acc: 0.9599 - Precision: 0.9641 - Recall: 0.9590 - F1: 0.9615\n",
      "Epoch 9/20 - Loss: 0.1045 - Acc: 0.9621 - Precision: 0.9664 - Recall: 0.9608 - F1: 0.9636\n",
      "Epoch 10/20 - Loss: 0.1028 - Acc: 0.9620 - Precision: 0.9661 - Recall: 0.9610 - F1: 0.9635\n",
      "Epoch 11/20 - Loss: 0.0982 - Acc: 0.9648 - Precision: 0.9693 - Recall: 0.9632 - F1: 0.9662\n",
      "Epoch 12/20 - Loss: 0.0961 - Acc: 0.9647 - Precision: 0.9679 - Recall: 0.9644 - F1: 0.9662\n",
      "Epoch 13/20 - Loss: 0.0929 - Acc: 0.9664 - Precision: 0.9698 - Recall: 0.9659 - F1: 0.9678\n",
      "Epoch 14/20 - Loss: 0.0918 - Acc: 0.9665 - Precision: 0.9701 - Recall: 0.9657 - F1: 0.9679\n",
      "Epoch 15/20 - Loss: 0.0918 - Acc: 0.9672 - Precision: 0.9704 - Recall: 0.9668 - F1: 0.9686\n",
      "Epoch 16/20 - Loss: 0.0864 - Acc: 0.9688 - Precision: 0.9714 - Recall: 0.9688 - F1: 0.9701\n",
      "Epoch 17/20 - Loss: 0.0876 - Acc: 0.9684 - Precision: 0.9713 - Recall: 0.9682 - F1: 0.9697\n",
      "Epoch 18/20 - Loss: 0.0858 - Acc: 0.9692 - Precision: 0.9718 - Recall: 0.9691 - F1: 0.9705\n",
      "Epoch 19/20 - Loss: 0.0815 - Acc: 0.9704 - Precision: 0.9736 - Recall: 0.9697 - F1: 0.9716\n",
      "Epoch 20/20 - Loss: 0.0835 - Acc: 0.9698 - Precision: 0.9727 - Recall: 0.9695 - F1: 0.9711\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9733\n",
      "Test Precision: 0.9761\n",
      "Test Recall: 0.9727\n",
      "Test F1 Score: 0.9744\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.97      0.97      0.97      4284\n",
      "        Fake       0.98      0.97      0.97      4696\n",
      "\n",
      "    accuracy                           0.97      8980\n",
      "   macro avg       0.97      0.97      0.97      8980\n",
      "weighted avg       0.97      0.97      0.97      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4172  112]\n",
      " [ 128 4568]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Embedding Method: Doc2Vec ===\n",
      "\n",
      "--- Preprocessing Step: Lowercase & Remove Punctuation ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding Doc2Vec with 'Lowercase & Remove Punctuation' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.1195 - Acc: 0.9599 - Precision: 0.9653 - Recall: 0.9577 - F1: 0.9615\n",
      "Epoch 2/20 - Loss: 0.0622 - Acc: 0.9790 - Precision: 0.9818 - Recall: 0.9780 - F1: 0.9799\n",
      "Epoch 3/20 - Loss: 0.0539 - Acc: 0.9815 - Precision: 0.9840 - Recall: 0.9806 - F1: 0.9823\n",
      "Epoch 4/20 - Loss: 0.0486 - Acc: 0.9825 - Precision: 0.9841 - Recall: 0.9824 - F1: 0.9832\n",
      "Epoch 5/20 - Loss: 0.0441 - Acc: 0.9844 - Precision: 0.9857 - Recall: 0.9845 - F1: 0.9851\n",
      "Epoch 6/20 - Loss: 0.0422 - Acc: 0.9858 - Precision: 0.9868 - Recall: 0.9859 - F1: 0.9864\n",
      "Epoch 7/20 - Loss: 0.0356 - Acc: 0.9882 - Precision: 0.9886 - Recall: 0.9888 - F1: 0.9887\n",
      "Epoch 8/20 - Loss: 0.0347 - Acc: 0.9879 - Precision: 0.9888 - Recall: 0.9881 - F1: 0.9884\n",
      "Epoch 9/20 - Loss: 0.0323 - Acc: 0.9892 - Precision: 0.9902 - Recall: 0.9891 - F1: 0.9897\n",
      "Epoch 10/20 - Loss: 0.0311 - Acc: 0.9894 - Precision: 0.9900 - Recall: 0.9898 - F1: 0.9899\n",
      "Epoch 11/20 - Loss: 0.0301 - Acc: 0.9898 - Precision: 0.9906 - Recall: 0.9898 - F1: 0.9902\n",
      "Epoch 12/20 - Loss: 0.0293 - Acc: 0.9905 - Precision: 0.9914 - Recall: 0.9903 - F1: 0.9909\n",
      "Epoch 13/20 - Loss: 0.0273 - Acc: 0.9908 - Precision: 0.9913 - Recall: 0.9911 - F1: 0.9912\n",
      "Epoch 14/20 - Loss: 0.0264 - Acc: 0.9911 - Precision: 0.9919 - Recall: 0.9911 - F1: 0.9915\n",
      "Epoch 15/20 - Loss: 0.0257 - Acc: 0.9910 - Precision: 0.9916 - Recall: 0.9911 - F1: 0.9913\n",
      "Epoch 16/20 - Loss: 0.0250 - Acc: 0.9913 - Precision: 0.9917 - Recall: 0.9916 - F1: 0.9917\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9889\n",
      "Test Precision: 0.9852\n",
      "Test Recall: 0.9936\n",
      "Test F1 Score: 0.9894\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      0.98      0.99      4284\n",
      "        Fake       0.99      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4214   70]\n",
      " [  30 4666]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Preprocessing Step: Lowercase, Remove Punctuation & Stopwords ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding Doc2Vec with 'Lowercase, Remove Punctuation & Stopwords' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.1471 - Acc: 0.9477 - Precision: 0.9500 - Recall: 0.9501 - F1: 0.9500\n",
      "Epoch 2/20 - Loss: 0.0840 - Acc: 0.9699 - Precision: 0.9737 - Recall: 0.9686 - F1: 0.9712\n",
      "Epoch 3/20 - Loss: 0.0704 - Acc: 0.9743 - Precision: 0.9768 - Recall: 0.9741 - F1: 0.9754\n",
      "Epoch 4/20 - Loss: 0.0641 - Acc: 0.9759 - Precision: 0.9784 - Recall: 0.9755 - F1: 0.9770\n",
      "Epoch 5/20 - Loss: 0.0583 - Acc: 0.9792 - Precision: 0.9810 - Recall: 0.9792 - F1: 0.9801\n",
      "Epoch 6/20 - Loss: 0.0543 - Acc: 0.9802 - Precision: 0.9823 - Recall: 0.9798 - F1: 0.9811\n",
      "Epoch 7/20 - Loss: 0.0498 - Acc: 0.9818 - Precision: 0.9837 - Recall: 0.9815 - F1: 0.9826\n",
      "Epoch 8/20 - Loss: 0.0471 - Acc: 0.9823 - Precision: 0.9842 - Recall: 0.9821 - F1: 0.9831\n",
      "Epoch 9/20 - Loss: 0.0461 - Acc: 0.9839 - Precision: 0.9845 - Recall: 0.9847 - F1: 0.9846\n",
      "Epoch 10/20 - Loss: 0.0414 - Acc: 0.9848 - Precision: 0.9859 - Recall: 0.9850 - F1: 0.9854\n",
      "Epoch 11/20 - Loss: 0.0425 - Acc: 0.9845 - Precision: 0.9863 - Recall: 0.9841 - F1: 0.9852\n",
      "Epoch 12/20 - Loss: 0.0380 - Acc: 0.9867 - Precision: 0.9880 - Recall: 0.9866 - F1: 0.9873\n",
      "Epoch 13/20 - Loss: 0.0381 - Acc: 0.9865 - Precision: 0.9877 - Recall: 0.9865 - F1: 0.9871\n",
      "Epoch 14/20 - Loss: 0.0370 - Acc: 0.9871 - Precision: 0.9882 - Recall: 0.9871 - F1: 0.9876\n",
      "Epoch 15/20 - Loss: 0.0366 - Acc: 0.9870 - Precision: 0.9888 - Recall: 0.9863 - F1: 0.9876\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9840\n",
      "Test Precision: 0.9780\n",
      "Test Recall: 0.9917\n",
      "Test F1 Score: 0.9848\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      0.98      0.98      4284\n",
      "        Fake       0.98      0.99      0.98      4696\n",
      "\n",
      "    accuracy                           0.98      8980\n",
      "   macro avg       0.98      0.98      0.98      8980\n",
      "weighted avg       0.98      0.98      0.98      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4179  105]\n",
      " [  39 4657]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Embedding Method: NaiveD2V ===\n",
      "\n",
      "--- Preprocessing Step: Lowercase & Remove Punctuation ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding NaiveD2V with 'Lowercase & Remove Punctuation' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.0883 - Acc: 0.9695 - Precision: 0.9606 - Recall: 0.9819 - F1: 0.9711\n",
      "Epoch 2/20 - Loss: 0.0228 - Acc: 0.9928 - Precision: 0.9942 - Recall: 0.9921 - F1: 0.9932\n",
      "Epoch 3/20 - Loss: 0.0194 - Acc: 0.9943 - Precision: 0.9958 - Recall: 0.9934 - F1: 0.9946\n",
      "Epoch 4/20 - Loss: 0.0157 - Acc: 0.9952 - Precision: 0.9963 - Recall: 0.9946 - F1: 0.9954\n",
      "Epoch 5/20 - Loss: 0.0131 - Acc: 0.9961 - Precision: 0.9970 - Recall: 0.9955 - F1: 0.9962\n",
      "Epoch 6/20 - Loss: 0.0100 - Acc: 0.9969 - Precision: 0.9972 - Recall: 0.9969 - F1: 0.9970\n",
      "Epoch 7/20 - Loss: 0.0090 - Acc: 0.9970 - Precision: 0.9975 - Recall: 0.9968 - F1: 0.9972\n",
      "Epoch 8/20 - Loss: 0.0076 - Acc: 0.9977 - Precision: 0.9981 - Recall: 0.9976 - F1: 0.9978\n",
      "Epoch 9/20 - Loss: 0.0074 - Acc: 0.9974 - Precision: 0.9978 - Recall: 0.9972 - F1: 0.9975\n",
      "Epoch 10/20 - Loss: 0.0066 - Acc: 0.9981 - Precision: 0.9983 - Recall: 0.9979 - F1: 0.9981\n",
      "Epoch 11/20 - Loss: 0.0055 - Acc: 0.9983 - Precision: 0.9987 - Recall: 0.9980 - F1: 0.9983\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9965\n",
      "Test Precision: 0.9974\n",
      "Test Recall: 0.9960\n",
      "Test F1 Score: 0.9967\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4272   12]\n",
      " [  19 4677]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Preprocessing Step: Lowercase, Remove Punctuation & Stopwords ---\n",
      "0        washington ( reuters ) - the head of a conserv...\n",
      "1        washington ( reuters ) - transgender people wi...\n",
      "2        washington ( reuters ) - the special counsel i...\n",
      "3        washington ( reuters ) - trump campaign advise...\n",
      "4        seattle/washington ( reuters ) - president don...\n",
      "                               ...                        \n",
      "44893    st century wire says as wire reported earlier ...\n",
      "44894    st century wire says it s a familiar theme . w...\n",
      "44895    patrick henningsen st century wireremember whe...\n",
      "44896    st century wire says al jazeera america will g...\n",
      "44897    st century wire says as wire predicted in its ...\n",
      "Name: text, Length: 44898, dtype: object\n",
      "Embedding NaiveD2V with 'Lowercase, Remove Punctuation & Stopwords' shape: (35918, 100)\n",
      "Epoch 1/20 - Loss: 0.0891 - Acc: 0.9698 - Precision: 0.9786 - Recall: 0.9634 - F1: 0.9709\n",
      "Epoch 2/20 - Loss: 0.0260 - Acc: 0.9919 - Precision: 0.9933 - Recall: 0.9912 - F1: 0.9923\n",
      "Epoch 3/20 - Loss: 0.0210 - Acc: 0.9930 - Precision: 0.9943 - Recall: 0.9923 - F1: 0.9933\n",
      "Epoch 4/20 - Loss: 0.0150 - Acc: 0.9954 - Precision: 0.9961 - Recall: 0.9952 - F1: 0.9956\n",
      "Epoch 5/20 - Loss: 0.0113 - Acc: 0.9964 - Precision: 0.9971 - Recall: 0.9961 - F1: 0.9966\n",
      "Epoch 6/20 - Loss: 0.0114 - Acc: 0.9962 - Precision: 0.9969 - Recall: 0.9960 - F1: 0.9964\n",
      "Epoch 7/20 - Loss: 0.0103 - Acc: 0.9966 - Precision: 0.9972 - Recall: 0.9963 - F1: 0.9968\n",
      "Epoch 8/20 - Loss: 0.0083 - Acc: 0.9976 - Precision: 0.9978 - Recall: 0.9976 - F1: 0.9977\n",
      "Epoch 9/20 - Loss: 0.0076 - Acc: 0.9975 - Precision: 0.9978 - Recall: 0.9974 - F1: 0.9976\n",
      "Epoch 10/20 - Loss: 0.0077 - Acc: 0.9974 - Precision: 0.9977 - Recall: 0.9974 - F1: 0.9976\n",
      "Early stopping triggered.\n",
      "\n",
      "Evaluation on Test Set:\n",
      "Test Accuracy: 0.9974\n",
      "Test Precision: 0.9983\n",
      "Test Recall: 0.9968\n",
      "Test F1 Score: 0.9975\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4276    8]\n",
      " [  15 4681]]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Summary of Selected Preprocessing-Embedding Combinations ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveD2V + Lowercase, Remove Punctuation &amp; Sto...</td>\n",
       "      <td>0.997439</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>0.996806</td>\n",
       "      <td>0.997549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveD2V + Lowercase &amp; Remove Punctuation</td>\n",
       "      <td>0.996548</td>\n",
       "      <td>0.997441</td>\n",
       "      <td>0.995954</td>\n",
       "      <td>0.996697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OneHot + Lowercase</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.998288</td>\n",
       "      <td>0.993612</td>\n",
       "      <td>0.995945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneHot + Lowercase &amp; Remove Punctuation</td>\n",
       "      <td>0.994432</td>\n",
       "      <td>0.994676</td>\n",
       "      <td>0.994676</td>\n",
       "      <td>0.994676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Word2Vec + Lowercase, Remove Punctuation &amp; Sto...</td>\n",
       "      <td>0.990089</td>\n",
       "      <td>0.994207</td>\n",
       "      <td>0.986797</td>\n",
       "      <td>0.990488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Doc2Vec + Lowercase &amp; Remove Punctuation</td>\n",
       "      <td>0.988864</td>\n",
       "      <td>0.985220</td>\n",
       "      <td>0.993612</td>\n",
       "      <td>0.989398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Word2Vec + Full Preprocessing</td>\n",
       "      <td>0.988530</td>\n",
       "      <td>0.987476</td>\n",
       "      <td>0.990630</td>\n",
       "      <td>0.989051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Word2Vec + Lowercase &amp; Remove Punctuation</td>\n",
       "      <td>0.987862</td>\n",
       "      <td>0.985602</td>\n",
       "      <td>0.991269</td>\n",
       "      <td>0.988428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Doc2Vec + Lowercase, Remove Punctuation &amp; Stop...</td>\n",
       "      <td>0.983964</td>\n",
       "      <td>0.977950</td>\n",
       "      <td>0.991695</td>\n",
       "      <td>0.984775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GloVe + Lowercase, Remove Punctuation &amp; Stopwords</td>\n",
       "      <td>0.979065</td>\n",
       "      <td>0.984731</td>\n",
       "      <td>0.975085</td>\n",
       "      <td>0.979884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GloVe + Full Preprocessing</td>\n",
       "      <td>0.973274</td>\n",
       "      <td>0.976068</td>\n",
       "      <td>0.972743</td>\n",
       "      <td>0.974403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GloVe + Lowercase &amp; Remove Punctuation</td>\n",
       "      <td>0.970713</td>\n",
       "      <td>0.968902</td>\n",
       "      <td>0.975298</td>\n",
       "      <td>0.972090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Combination  Accuracy  Precision  \\\n",
       "0   NaiveD2V + Lowercase, Remove Punctuation & Sto...  0.997439   0.998294   \n",
       "1           NaiveD2V + Lowercase & Remove Punctuation  0.996548   0.997441   \n",
       "2                                  OneHot + Lowercase  0.995768   0.998288   \n",
       "3             OneHot + Lowercase & Remove Punctuation  0.994432   0.994676   \n",
       "4   Word2Vec + Lowercase, Remove Punctuation & Sto...  0.990089   0.994207   \n",
       "5            Doc2Vec + Lowercase & Remove Punctuation  0.988864   0.985220   \n",
       "6                       Word2Vec + Full Preprocessing  0.988530   0.987476   \n",
       "7           Word2Vec + Lowercase & Remove Punctuation  0.987862   0.985602   \n",
       "8   Doc2Vec + Lowercase, Remove Punctuation & Stop...  0.983964   0.977950   \n",
       "9   GloVe + Lowercase, Remove Punctuation & Stopwords  0.979065   0.984731   \n",
       "10                         GloVe + Full Preprocessing  0.973274   0.976068   \n",
       "11             GloVe + Lowercase & Remove Punctuation  0.970713   0.968902   \n",
       "\n",
       "      Recall  F1 Score  \n",
       "0   0.996806  0.997549  \n",
       "1   0.995954  0.996697  \n",
       "2   0.993612  0.995945  \n",
       "3   0.994676  0.994676  \n",
       "4   0.986797  0.990488  \n",
       "5   0.993612  0.989398  \n",
       "6   0.990630  0.989051  \n",
       "7   0.991269  0.988428  \n",
       "8   0.991695  0.984775  \n",
       "9   0.975085  0.979884  \n",
       "10  0.972743  0.974403  \n",
       "11  0.975298  0.972090  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 10: Train and Evaluate Selected Preprocessing-Embedding Combinations\n",
    "\n",
    "# Define a mapping of embedding methods to suitable preprocessing steps\n",
    "embedding_preprocessing_map = {\n",
    "    'OneHot': ['Lowercase', 'Lowercase & Remove Punctuation'],\n",
    "    'Word2Vec': ['Lowercase & Remove Punctuation', 'Lowercase, Remove Punctuation & Stopwords', 'Full Preprocessing'],\n",
    "    'GloVe': ['Lowercase & Remove Punctuation', 'Lowercase, Remove Punctuation & Stopwords', 'Full Preprocessing'],\n",
    "    'Doc2Vec': ['Lowercase & Remove Punctuation', 'Lowercase, Remove Punctuation & Stopwords'],\n",
    "    'NaiveD2V': ['Lowercase & Remove Punctuation', 'Lowercase, Remove Punctuation & Stopwords']\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "# Iterate over each embedding method and their corresponding preprocessing steps\n",
    "for embed_method, prep_steps in embedding_preprocessing_map.items():\n",
    "    print(f\"=== Embedding Method: {embed_method} ===\")\n",
    "\n",
    "\n",
    "    \n",
    "    for prep_name in prep_steps:\n",
    "        print(f\"\\n--- Preprocessing Step: {prep_name} ---\")\n",
    "\n",
    "        print(processed_texts['Lowercase'])\n",
    "        # Prepare features and labels\n",
    "        X = processed_texts[prep_name]\n",
    "        y = df['label']\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Apply embedding\n",
    "        try:\n",
    "            if embed_method == 'GloVe':\n",
    "                X_train_emb, X_test_emb = glove_embed(X_train, X_test, embeddings_glove, embedding_dim=100)\n",
    "            elif embed_method in ['Doc2Vec', 'NaiveD2V']:\n",
    "                X_train_emb, X_test_emb, _ = apply_embedding(embed_method, processed_texts, X_train, X_test)\n",
    "            else:\n",
    "                X_train_emb, X_test_emb, _ = apply_embedding(embed_method, processed_texts, X_train, X_test)\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding {embed_method} with preprocessing '{prep_name}' failed with error: {e}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Embedding {embed_method} with '{prep_name}' shape: {X_train_emb.shape}\")\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_loader, test_loader = create_dataloaders(X_train_emb, X_test_emb, y_train, y_test, batch_size=64)\n",
    "        \n",
    "        # Define model architecture\n",
    "        input_size = X_train_emb.shape[1]\n",
    "        hidden_sizes = [128, 64]  # Default hidden layers; can be adjusted\n",
    "        model = FFNN(input_size=input_size, hidden_sizes=hidden_sizes, dropout=0.5)\n",
    "        \n",
    "        # Define loss and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        history = train_model_with_early_stopping(\n",
    "            model, train_loader, criterion, optimizer,\n",
    "            epochs=20, device=device, patience=3, metric='f1'\n",
    "        )\n",
    "        \n",
    "        # Evaluate the model\n",
    "        print(\"\\nEvaluation on Test Set:\")\n",
    "        acc, precision, recall, f1, cm, report = evaluate_model_detailed(model, test_loader, device)\n",
    "        \n",
    "        # Store the results\n",
    "        key = f\"{embed_method} + {prep_name}\"\n",
    "        results[key] = {\n",
    "            'Accuracy': acc,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'Confusion Matrix': cm,\n",
    "            'Classification Report': report,\n",
    "            'Training History': history\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Display a summary of results\n",
    "summary = pd.DataFrame({\n",
    "    'Combination': list(results.keys()),\n",
    "    'Accuracy': [v['Accuracy'] for v in results.values()],\n",
    "    'Precision': [v['Precision'] for v in results.values()],\n",
    "    'Recall': [v['Recall'] for v in results.values()],\n",
    "    'F1 Score': [v['F1 Score'] for v in results.values()]\n",
    "})\n",
    "\n",
    "print(\"=== Summary of Selected Preprocessing-Embedding Combinations ===\")\n",
    "display(summary.sort_values(by='F1 Score', ascending=False).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540fb2e-513b-411d-a51c-cc3285b20a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27111a07-8e33-4a6b-9dfd-1eb249c41cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Preprocessing + Embedding Combination: NaiveD2V + Lowercase, Remove Punctuation & Stopwords\n",
      "Accuracy: 0.9974\n",
      "Precision: 0.9983\n",
      "Recall: 0.9968\n",
      "F1 Score: 0.9975\n",
      "\n",
      "Details of the Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4276    8]\n",
      " [  15 4681]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Analyze and Select Best Preprocessing-Embedding Pairs\n",
    "\n",
    "# Extract the best combination based on F1 Score\n",
    "best_combination = summary.sort_values(by='F1 Score', ascending=False).iloc[0]\n",
    "print(f\"Best Preprocessing + Embedding Combination: {best_combination['Combination']}\")\n",
    "print(f\"Accuracy: {best_combination['Accuracy']:.4f}\")\n",
    "print(f\"Precision: {best_combination['Precision']:.4f}\")\n",
    "print(f\"Recall: {best_combination['Recall']:.4f}\")\n",
    "print(f\"F1 Score: {best_combination['F1 Score']:.4f}\")\n",
    "\n",
    "# Identify the preprocessing and embedding method\n",
    "best_prep, best_embed = best_combination['Combination'].split(' + ')\n",
    "\n",
    "print(\"\\nDetails of the Best Model:\")\n",
    "print(results[best_combination['Combination']]['Classification Report'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(results[best_combination['Combination']]['Confusion Matrix'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9bd5a20c-ae24-437c-a515-5fd21bd8e5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Best Preprocessing: Lowercase, Remove Punctuation & Stopwords\n",
      "Selected Best Embedding: NaiveD2V\n",
      "\n",
      "Reapplying Best Preprocessing: Lowercase, Remove Punctuation & Stopwords and Embedding: NaiveD2V\n",
      "Embedding NaiveD2V shape: (35918, 100)\n",
      "\n",
      "Starting Randomized Hyperparameter Tuning...\n",
      "\n",
      "--- Hyperparameter Combination 1/20 ---\n",
      "Parameters: {'patience': 5, 'learning_rate': 0.001, 'hidden_sizes': [512, 256, 128], 'epochs': 20, 'dropout': 0.5}\n",
      "Epoch 1/20 - Loss: 0.0635 - Acc: 0.9771 - F1: 0.9783\n",
      "Epoch 2/20 - Loss: 0.0223 - Acc: 0.9928 - F1: 0.9931\n",
      "Epoch 3/20 - Loss: 0.0148 - Acc: 0.9950 - F1: 0.9953\n",
      "Epoch 4/20 - Loss: 0.0104 - Acc: 0.9964 - F1: 0.9965\n",
      "Epoch 5/20 - Loss: 0.0097 - Acc: 0.9967 - F1: 0.9969\n",
      "Epoch 6/20 - Loss: 0.0082 - Acc: 0.9976 - F1: 0.9977\n",
      "Epoch 7/20 - Loss: 0.0079 - Acc: 0.9975 - F1: 0.9976\n",
      "Epoch 8/20 - Loss: 0.0070 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 9/20 - Loss: 0.0068 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 10/20 - Loss: 0.0062 - Acc: 0.9980 - F1: 0.9981\n",
      "Epoch 11/20 - Loss: 0.0040 - Acc: 0.9989 - F1: 0.9989\n",
      "Epoch 12/20 - Loss: 0.0060 - Acc: 0.9979 - F1: 0.9980\n",
      "Epoch 13/20 - Loss: 0.0029 - Acc: 0.9991 - F1: 0.9991\n",
      "Epoch 14/20 - Loss: 0.0041 - Acc: 0.9986 - F1: 0.9987\n",
      "Epoch 15/20 - Loss: 0.0041 - Acc: 0.9987 - F1: 0.9987\n",
      "Epoch 16/20 - Loss: 0.0050 - Acc: 0.9982 - F1: 0.9983\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9971\n",
      "Test Precision: 0.9981\n",
      "Test Recall: 0.9964\n",
      "Test F1 Score: 0.9972\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4275    9]\n",
      " [  17 4679]]\n",
      "New best model found!\n",
      "\n",
      "--- Hyperparameter Combination 2/20 ---\n",
      "Parameters: {'patience': 5, 'learning_rate': 0.001, 'hidden_sizes': [256, 128], 'epochs': 30, 'dropout': 0.3}\n",
      "Epoch 1/30 - Loss: 0.0585 - Acc: 0.9800 - F1: 0.9809\n",
      "Epoch 2/30 - Loss: 0.0205 - Acc: 0.9937 - F1: 0.9940\n",
      "Epoch 3/30 - Loss: 0.0130 - Acc: 0.9960 - F1: 0.9961\n",
      "Epoch 4/30 - Loss: 0.0093 - Acc: 0.9967 - F1: 0.9969\n",
      "Epoch 5/30 - Loss: 0.0071 - Acc: 0.9975 - F1: 0.9976\n",
      "Epoch 6/30 - Loss: 0.0043 - Acc: 0.9987 - F1: 0.9988\n",
      "Epoch 7/30 - Loss: 0.0049 - Acc: 0.9985 - F1: 0.9985\n",
      "Epoch 8/30 - Loss: 0.0039 - Acc: 0.9987 - F1: 0.9988\n",
      "Epoch 9/30 - Loss: 0.0035 - Acc: 0.9990 - F1: 0.9990\n",
      "Epoch 10/30 - Loss: 0.0034 - Acc: 0.9990 - F1: 0.9990\n",
      "Epoch 11/30 - Loss: 0.0033 - Acc: 0.9990 - F1: 0.9991\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9967\n",
      "Test Precision: 0.9972\n",
      "Test Recall: 0.9964\n",
      "Test F1 Score: 0.9968\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4271   13]\n",
      " [  17 4679]]\n",
      "\n",
      "--- Hyperparameter Combination 3/20 ---\n",
      "Parameters: {'patience': 7, 'learning_rate': 0.0005, 'hidden_sizes': [256, 128, 64], 'epochs': 40, 'dropout': 0.7}\n",
      "Epoch 1/40 - Loss: 0.2016 - Acc: 0.9053 - F1: 0.9099\n",
      "Epoch 2/40 - Loss: 0.0402 - Acc: 0.9891 - F1: 0.9896\n",
      "Epoch 3/40 - Loss: 0.0339 - Acc: 0.9908 - F1: 0.9912\n",
      "Epoch 4/40 - Loss: 0.0295 - Acc: 0.9923 - F1: 0.9927\n",
      "Epoch 5/40 - Loss: 0.0250 - Acc: 0.9936 - F1: 0.9939\n",
      "Epoch 6/40 - Loss: 0.0215 - Acc: 0.9941 - F1: 0.9943\n",
      "Epoch 7/40 - Loss: 0.0199 - Acc: 0.9943 - F1: 0.9946\n",
      "Epoch 8/40 - Loss: 0.0181 - Acc: 0.9948 - F1: 0.9950\n",
      "Epoch 9/40 - Loss: 0.0150 - Acc: 0.9954 - F1: 0.9956\n",
      "Epoch 10/40 - Loss: 0.0145 - Acc: 0.9959 - F1: 0.9961\n",
      "Epoch 11/40 - Loss: 0.0135 - Acc: 0.9962 - F1: 0.9963\n",
      "Epoch 12/40 - Loss: 0.0121 - Acc: 0.9965 - F1: 0.9966\n",
      "Epoch 13/40 - Loss: 0.0111 - Acc: 0.9968 - F1: 0.9969\n",
      "Epoch 14/40 - Loss: 0.0111 - Acc: 0.9968 - F1: 0.9969\n",
      "Epoch 15/40 - Loss: 0.0095 - Acc: 0.9972 - F1: 0.9973\n",
      "Epoch 16/40 - Loss: 0.0096 - Acc: 0.9972 - F1: 0.9973\n",
      "Epoch 17/40 - Loss: 0.0095 - Acc: 0.9973 - F1: 0.9974\n",
      "Epoch 18/40 - Loss: 0.0123 - Acc: 0.9976 - F1: 0.9977\n",
      "Epoch 19/40 - Loss: 0.0075 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 20/40 - Loss: 0.0087 - Acc: 0.9977 - F1: 0.9978\n",
      "Epoch 21/40 - Loss: 0.0077 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 22/40 - Loss: 0.0078 - Acc: 0.9976 - F1: 0.9977\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9967\n",
      "Test Precision: 0.9970\n",
      "Test Recall: 0.9966\n",
      "Test F1 Score: 0.9968\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4270   14]\n",
      " [  16 4680]]\n",
      "\n",
      "--- Hyperparameter Combination 4/20 ---\n",
      "Parameters: {'patience': 7, 'learning_rate': 0.001, 'hidden_sizes': [128, 64, 32], 'epochs': 30, 'dropout': 0.3}\n",
      "Epoch 1/30 - Loss: 0.0797 - Acc: 0.9686 - F1: 0.9705\n",
      "Epoch 2/30 - Loss: 0.0246 - Acc: 0.9923 - F1: 0.9927\n",
      "Epoch 3/30 - Loss: 0.0180 - Acc: 0.9946 - F1: 0.9948\n",
      "Epoch 4/30 - Loss: 0.0130 - Acc: 0.9961 - F1: 0.9963\n",
      "Epoch 5/30 - Loss: 0.0104 - Acc: 0.9969 - F1: 0.9970\n",
      "Epoch 6/30 - Loss: 0.0074 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 7/30 - Loss: 0.0070 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 8/30 - Loss: 0.0063 - Acc: 0.9980 - F1: 0.9981\n",
      "Epoch 9/30 - Loss: 0.0053 - Acc: 0.9983 - F1: 0.9984\n",
      "Epoch 10/30 - Loss: 0.0052 - Acc: 0.9985 - F1: 0.9985\n",
      "Epoch 11/30 - Loss: 0.0043 - Acc: 0.9988 - F1: 0.9989\n",
      "Epoch 12/30 - Loss: 0.0043 - Acc: 0.9988 - F1: 0.9988\n",
      "Epoch 13/30 - Loss: 0.0049 - Acc: 0.9984 - F1: 0.9985\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9967\n",
      "Test Precision: 0.9970\n",
      "Test Recall: 0.9966\n",
      "Test F1 Score: 0.9968\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4270   14]\n",
      " [  16 4680]]\n",
      "\n",
      "--- Hyperparameter Combination 5/20 ---\n",
      "Parameters: {'patience': 5, 'learning_rate': 0.001, 'hidden_sizes': [512, 256, 128], 'epochs': 30, 'dropout': 0.7}\n",
      "Epoch 1/30 - Loss: 0.0984 - Acc: 0.9598 - F1: 0.9610\n",
      "Epoch 2/30 - Loss: 0.0314 - Acc: 0.9905 - F1: 0.9909\n",
      "Epoch 3/30 - Loss: 0.0232 - Acc: 0.9923 - F1: 0.9926\n",
      "Epoch 4/30 - Loss: 0.0204 - Acc: 0.9938 - F1: 0.9941\n",
      "Epoch 5/30 - Loss: 0.0184 - Acc: 0.9942 - F1: 0.9945\n",
      "Epoch 6/30 - Loss: 0.0159 - Acc: 0.9951 - F1: 0.9953\n",
      "Epoch 7/30 - Loss: 0.0126 - Acc: 0.9960 - F1: 0.9961\n",
      "Epoch 8/30 - Loss: 0.0137 - Acc: 0.9957 - F1: 0.9958\n",
      "Epoch 9/30 - Loss: 0.0126 - Acc: 0.9965 - F1: 0.9967\n",
      "Epoch 10/30 - Loss: 0.0119 - Acc: 0.9965 - F1: 0.9966\n",
      "Epoch 11/30 - Loss: 0.0098 - Acc: 0.9971 - F1: 0.9972\n",
      "Epoch 12/30 - Loss: 0.0093 - Acc: 0.9969 - F1: 0.9971\n",
      "Epoch 13/30 - Loss: 0.0094 - Acc: 0.9972 - F1: 0.9974\n",
      "Epoch 14/30 - Loss: 0.0092 - Acc: 0.9973 - F1: 0.9974\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9965\n",
      "Test Precision: 0.9968\n",
      "Test Recall: 0.9966\n",
      "Test F1 Score: 0.9967\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4269   15]\n",
      " [  16 4680]]\n",
      "\n",
      "--- Hyperparameter Combination 6/20 ---\n",
      "Parameters: {'patience': 7, 'learning_rate': 0.0005, 'hidden_sizes': [256, 128], 'epochs': 30, 'dropout': 0.3}\n",
      "Epoch 1/30 - Loss: 0.0819 - Acc: 0.9761 - F1: 0.9773\n",
      "Epoch 2/30 - Loss: 0.0231 - Acc: 0.9926 - F1: 0.9929\n",
      "Epoch 3/30 - Loss: 0.0170 - Acc: 0.9948 - F1: 0.9951\n",
      "Epoch 4/30 - Loss: 0.0132 - Acc: 0.9961 - F1: 0.9962\n",
      "Epoch 5/30 - Loss: 0.0102 - Acc: 0.9966 - F1: 0.9968\n",
      "Epoch 6/30 - Loss: 0.0075 - Acc: 0.9977 - F1: 0.9978\n",
      "Epoch 7/30 - Loss: 0.0051 - Acc: 0.9985 - F1: 0.9985\n",
      "Epoch 8/30 - Loss: 0.0043 - Acc: 0.9989 - F1: 0.9990\n",
      "Epoch 9/30 - Loss: 0.0036 - Acc: 0.9989 - F1: 0.9990\n",
      "Epoch 10/30 - Loss: 0.0034 - Acc: 0.9989 - F1: 0.9989\n",
      "Epoch 11/30 - Loss: 0.0028 - Acc: 0.9993 - F1: 0.9993\n",
      "Epoch 12/30 - Loss: 0.0030 - Acc: 0.9991 - F1: 0.9992\n",
      "Epoch 13/30 - Loss: 0.0027 - Acc: 0.9991 - F1: 0.9992\n",
      "Epoch 14/30 - Loss: 0.0018 - Acc: 0.9996 - F1: 0.9996\n",
      "Epoch 15/30 - Loss: 0.0017 - Acc: 0.9996 - F1: 0.9996\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9968\n",
      "Test Precision: 0.9977\n",
      "Test Recall: 0.9962\n",
      "Test F1 Score: 0.9969\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4273   11]\n",
      " [  18 4678]]\n",
      "\n",
      "--- Hyperparameter Combination 7/20 ---\n",
      "Parameters: {'patience': 3, 'learning_rate': 0.005, 'hidden_sizes': [512, 256, 128], 'epochs': 30, 'dropout': 0.5}\n",
      "Epoch 1/30 - Loss: 0.0514 - Acc: 0.9830 - F1: 0.9837\n",
      "Epoch 2/30 - Loss: 0.0325 - Acc: 0.9906 - F1: 0.9910\n",
      "Epoch 3/30 - Loss: 0.0321 - Acc: 0.9915 - F1: 0.9919\n",
      "Epoch 4/30 - Loss: 0.0335 - Acc: 0.9917 - F1: 0.9921\n",
      "Epoch 5/30 - Loss: 0.0323 - Acc: 0.9923 - F1: 0.9926\n",
      "Epoch 6/30 - Loss: 0.0391 - Acc: 0.9923 - F1: 0.9926\n",
      "Epoch 7/30 - Loss: 0.0336 - Acc: 0.9921 - F1: 0.9924\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9900\n",
      "Test Precision: 0.9993\n",
      "Test Recall: 0.9815\n",
      "Test F1 Score: 0.9903\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.98      1.00      0.99      4284\n",
      "        Fake       1.00      0.98      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4281    3]\n",
      " [  87 4609]]\n",
      "\n",
      "--- Hyperparameter Combination 8/20 ---\n",
      "Parameters: {'patience': 5, 'learning_rate': 0.005, 'hidden_sizes': [512, 256, 128], 'epochs': 20, 'dropout': 0.7}\n",
      "Epoch 1/20 - Loss: 0.0878 - Acc: 0.9718 - F1: 0.9731\n",
      "Epoch 2/20 - Loss: 0.0705 - Acc: 0.9852 - F1: 0.9858\n",
      "Epoch 3/20 - Loss: 0.0703 - Acc: 0.9856 - F1: 0.9862\n",
      "Epoch 4/20 - Loss: 0.0845 - Acc: 0.9862 - F1: 0.9867\n",
      "Epoch 5/20 - Loss: 0.1144 - Acc: 0.9856 - F1: 0.9862\n",
      "Epoch 6/20 - Loss: 0.1001 - Acc: 0.9865 - F1: 0.9871\n",
      "Epoch 7/20 - Loss: 0.1073 - Acc: 0.9866 - F1: 0.9871\n",
      "Epoch 8/20 - Loss: 0.1410 - Acc: 0.9874 - F1: 0.9879\n",
      "Epoch 9/20 - Loss: 0.1346 - Acc: 0.9883 - F1: 0.9888\n",
      "Epoch 10/20 - Loss: 0.1491 - Acc: 0.9879 - F1: 0.9884\n",
      "Epoch 11/20 - Loss: 0.1663 - Acc: 0.9849 - F1: 0.9855\n",
      "Epoch 12/20 - Loss: 0.1720 - Acc: 0.9842 - F1: 0.9848\n",
      "Epoch 13/20 - Loss: 0.2074 - Acc: 0.9857 - F1: 0.9862\n",
      "Epoch 14/20 - Loss: 0.2209 - Acc: 0.9874 - F1: 0.9878\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9949\n",
      "Test Precision: 0.9957\n",
      "Test Recall: 0.9945\n",
      "Test F1 Score: 0.9951\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      1.00      0.99      4284\n",
      "        Fake       1.00      0.99      1.00      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4264   20]\n",
      " [  26 4670]]\n",
      "\n",
      "--- Hyperparameter Combination 9/20 ---\n",
      "Parameters: {'patience': 3, 'learning_rate': 0.0001, 'hidden_sizes': [256, 128, 64], 'epochs': 40, 'dropout': 0.5}\n",
      "Epoch 1/40 - Loss: 0.3448 - Acc: 0.8604 - F1: 0.8738\n",
      "Epoch 2/40 - Loss: 0.0486 - Acc: 0.9862 - F1: 0.9868\n",
      "Epoch 3/40 - Loss: 0.0379 - Acc: 0.9892 - F1: 0.9897\n",
      "Epoch 4/40 - Loss: 0.0352 - Acc: 0.9907 - F1: 0.9911\n",
      "Epoch 5/40 - Loss: 0.0294 - Acc: 0.9917 - F1: 0.9921\n",
      "Epoch 6/40 - Loss: 0.0262 - Acc: 0.9921 - F1: 0.9925\n",
      "Epoch 7/40 - Loss: 0.0237 - Acc: 0.9929 - F1: 0.9932\n",
      "Epoch 8/40 - Loss: 0.0224 - Acc: 0.9936 - F1: 0.9939\n",
      "Epoch 9/40 - Loss: 0.0215 - Acc: 0.9938 - F1: 0.9941\n",
      "Epoch 10/40 - Loss: 0.0216 - Acc: 0.9940 - F1: 0.9942\n",
      "Epoch 11/40 - Loss: 0.0187 - Acc: 0.9947 - F1: 0.9949\n",
      "Epoch 12/40 - Loss: 0.0188 - Acc: 0.9943 - F1: 0.9946\n",
      "Epoch 13/40 - Loss: 0.0163 - Acc: 0.9952 - F1: 0.9954\n",
      "Epoch 14/40 - Loss: 0.0165 - Acc: 0.9952 - F1: 0.9954\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9947\n",
      "Test Precision: 0.9955\n",
      "Test Recall: 0.9943\n",
      "Test F1 Score: 0.9949\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      1.00      0.99      4284\n",
      "        Fake       1.00      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4263   21]\n",
      " [  27 4669]]\n",
      "\n",
      "--- Hyperparameter Combination 10/20 ---\n",
      "Parameters: {'patience': 7, 'learning_rate': 0.005, 'hidden_sizes': [256, 128], 'epochs': 20, 'dropout': 0.7}\n",
      "Epoch 1/20 - Loss: 0.0647 - Acc: 0.9778 - F1: 0.9788\n",
      "Epoch 2/20 - Loss: 0.0376 - Acc: 0.9888 - F1: 0.9892\n",
      "Epoch 3/20 - Loss: 0.0344 - Acc: 0.9904 - F1: 0.9908\n",
      "Epoch 4/20 - Loss: 0.0271 - Acc: 0.9916 - F1: 0.9919\n",
      "Epoch 5/20 - Loss: 0.0256 - Acc: 0.9917 - F1: 0.9920\n",
      "Epoch 6/20 - Loss: 0.0267 - Acc: 0.9923 - F1: 0.9926\n",
      "Epoch 7/20 - Loss: 0.0350 - Acc: 0.9929 - F1: 0.9932\n",
      "Epoch 8/20 - Loss: 0.0245 - Acc: 0.9930 - F1: 0.9933\n",
      "Epoch 9/20 - Loss: 0.0256 - Acc: 0.9929 - F1: 0.9932\n",
      "Epoch 10/20 - Loss: 0.0285 - Acc: 0.9922 - F1: 0.9925\n",
      "Epoch 11/20 - Loss: 0.0190 - Acc: 0.9948 - F1: 0.9951\n",
      "Epoch 12/20 - Loss: 0.0202 - Acc: 0.9941 - F1: 0.9943\n",
      "Epoch 13/20 - Loss: 0.0304 - Acc: 0.9926 - F1: 0.9930\n",
      "Epoch 14/20 - Loss: 0.0222 - Acc: 0.9945 - F1: 0.9947\n",
      "Epoch 15/20 - Loss: 0.0303 - Acc: 0.9937 - F1: 0.9940\n",
      "Epoch 16/20 - Loss: 0.0318 - Acc: 0.9942 - F1: 0.9945\n",
      "Epoch 17/20 - Loss: 0.0194 - Acc: 0.9943 - F1: 0.9946\n",
      "Epoch 18/20 - Loss: 0.0195 - Acc: 0.9950 - F1: 0.9953\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9961\n",
      "Test Precision: 0.9983\n",
      "Test Recall: 0.9943\n",
      "Test F1 Score: 0.9963\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      1.00      1.00      4284\n",
      "        Fake       1.00      0.99      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4276    8]\n",
      " [  27 4669]]\n",
      "\n",
      "--- Hyperparameter Combination 11/20 ---\n",
      "Parameters: {'patience': 3, 'learning_rate': 0.0001, 'hidden_sizes': [128, 64], 'epochs': 20, 'dropout': 0.3}\n",
      "Epoch 1/20 - Loss: 0.3485 - Acc: 0.9063 - F1: 0.9130\n",
      "Epoch 2/20 - Loss: 0.0526 - Acc: 0.9889 - F1: 0.9894\n",
      "Epoch 3/20 - Loss: 0.0353 - Acc: 0.9902 - F1: 0.9906\n",
      "Epoch 4/20 - Loss: 0.0289 - Acc: 0.9919 - F1: 0.9922\n",
      "Epoch 5/20 - Loss: 0.0269 - Acc: 0.9923 - F1: 0.9926\n",
      "Epoch 6/20 - Loss: 0.0249 - Acc: 0.9927 - F1: 0.9930\n",
      "Epoch 7/20 - Loss: 0.0235 - Acc: 0.9928 - F1: 0.9932\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9932\n",
      "Test Precision: 0.9949\n",
      "Test Recall: 0.9921\n",
      "Test F1 Score: 0.9935\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      0.99      0.99      4284\n",
      "        Fake       0.99      0.99      0.99      4696\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4260   24]\n",
      " [  37 4659]]\n",
      "\n",
      "--- Hyperparameter Combination 12/20 ---\n",
      "Parameters: {'patience': 3, 'learning_rate': 0.005, 'hidden_sizes': [512, 256, 128], 'epochs': 30, 'dropout': 0.3}\n",
      "Epoch 1/30 - Loss: 0.0436 - Acc: 0.9871 - F1: 0.9876\n",
      "Epoch 2/30 - Loss: 0.0222 - Acc: 0.9932 - F1: 0.9935\n",
      "Epoch 3/30 - Loss: 0.0245 - Acc: 0.9944 - F1: 0.9946\n",
      "Epoch 4/30 - Loss: 0.0197 - Acc: 0.9948 - F1: 0.9950\n",
      "Epoch 5/30 - Loss: 0.0147 - Acc: 0.9957 - F1: 0.9959\n",
      "Epoch 6/30 - Loss: 0.0159 - Acc: 0.9951 - F1: 0.9953\n",
      "Epoch 7/30 - Loss: 0.0111 - Acc: 0.9969 - F1: 0.9970\n",
      "Epoch 8/30 - Loss: 0.0148 - Acc: 0.9965 - F1: 0.9966\n",
      "Epoch 9/30 - Loss: 0.0317 - Acc: 0.9948 - F1: 0.9950\n",
      "Epoch 10/30 - Loss: 0.0104 - Acc: 0.9973 - F1: 0.9974\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9970\n",
      "Test Precision: 0.9966\n",
      "Test Recall: 0.9977\n",
      "Test F1 Score: 0.9971\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4268   16]\n",
      " [  11 4685]]\n",
      "\n",
      "--- Hyperparameter Combination 13/20 ---\n",
      "Parameters: {'patience': 7, 'learning_rate': 0.001, 'hidden_sizes': [512, 256, 128], 'epochs': 20, 'dropout': 0.7}\n",
      "Epoch 1/20 - Loss: 0.0967 - Acc: 0.9612 - F1: 0.9630\n",
      "Epoch 2/20 - Loss: 0.0304 - Acc: 0.9917 - F1: 0.9920\n",
      "Epoch 3/20 - Loss: 0.0257 - Acc: 0.9924 - F1: 0.9928\n",
      "Epoch 4/20 - Loss: 0.0209 - Acc: 0.9932 - F1: 0.9935\n",
      "Epoch 5/20 - Loss: 0.0173 - Acc: 0.9949 - F1: 0.9951\n",
      "Epoch 6/20 - Loss: 0.0158 - Acc: 0.9951 - F1: 0.9953\n",
      "Epoch 7/20 - Loss: 0.0144 - Acc: 0.9954 - F1: 0.9956\n",
      "Epoch 8/20 - Loss: 0.0132 - Acc: 0.9957 - F1: 0.9959\n",
      "Epoch 9/20 - Loss: 0.0115 - Acc: 0.9965 - F1: 0.9967\n",
      "Epoch 10/20 - Loss: 0.0096 - Acc: 0.9968 - F1: 0.9969\n",
      "Epoch 11/20 - Loss: 0.0114 - Acc: 0.9963 - F1: 0.9965\n",
      "Epoch 12/20 - Loss: 0.0096 - Acc: 0.9968 - F1: 0.9969\n",
      "Epoch 13/20 - Loss: 0.0106 - Acc: 0.9969 - F1: 0.9971\n",
      "Epoch 14/20 - Loss: 0.0084 - Acc: 0.9974 - F1: 0.9976\n",
      "Epoch 15/20 - Loss: 0.0086 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 16/20 - Loss: 0.0115 - Acc: 0.9974 - F1: 0.9975\n",
      "Epoch 17/20 - Loss: 0.0072 - Acc: 0.9976 - F1: 0.9977\n",
      "Epoch 18/20 - Loss: 0.0068 - Acc: 0.9981 - F1: 0.9982\n",
      "Epoch 19/20 - Loss: 0.0086 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 20/20 - Loss: 0.0085 - Acc: 0.9974 - F1: 0.9975\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9972\n",
      "Test Precision: 0.9981\n",
      "Test Recall: 0.9966\n",
      "Test F1 Score: 0.9973\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4275    9]\n",
      " [  16 4680]]\n",
      "New best model found!\n",
      "\n",
      "--- Hyperparameter Combination 14/20 ---\n",
      "Parameters: {'patience': 3, 'learning_rate': 0.0005, 'hidden_sizes': [256, 128], 'epochs': 30, 'dropout': 0.3}\n",
      "Epoch 1/30 - Loss: 0.0797 - Acc: 0.9785 - F1: 0.9794\n",
      "Epoch 2/30 - Loss: 0.0219 - Acc: 0.9929 - F1: 0.9932\n",
      "Epoch 3/30 - Loss: 0.0159 - Acc: 0.9950 - F1: 0.9953\n",
      "Epoch 4/30 - Loss: 0.0124 - Acc: 0.9959 - F1: 0.9961\n",
      "Epoch 5/30 - Loss: 0.0086 - Acc: 0.9974 - F1: 0.9975\n",
      "Epoch 6/30 - Loss: 0.0074 - Acc: 0.9974 - F1: 0.9976\n",
      "Epoch 7/30 - Loss: 0.0052 - Acc: 0.9986 - F1: 0.9986\n",
      "Epoch 8/30 - Loss: 0.0040 - Acc: 0.9988 - F1: 0.9989\n",
      "Epoch 9/30 - Loss: 0.0038 - Acc: 0.9989 - F1: 0.9990\n",
      "Epoch 10/30 - Loss: 0.0029 - Acc: 0.9991 - F1: 0.9992\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9967\n",
      "Test Precision: 0.9958\n",
      "Test Recall: 0.9979\n",
      "Test F1 Score: 0.9968\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4264   20]\n",
      " [  10 4686]]\n",
      "\n",
      "--- Hyperparameter Combination 15/20 ---\n",
      "Parameters: {'patience': 7, 'learning_rate': 0.0001, 'hidden_sizes': [128, 64, 32], 'epochs': 30, 'dropout': 0.5}\n",
      "Epoch 1/30 - Loss: 0.4926 - Acc: 0.7811 - F1: 0.8020\n",
      "Epoch 2/30 - Loss: 0.0825 - Acc: 0.9789 - F1: 0.9797\n",
      "Epoch 3/30 - Loss: 0.0528 - Acc: 0.9862 - F1: 0.9868\n",
      "Epoch 4/30 - Loss: 0.0464 - Acc: 0.9884 - F1: 0.9889\n",
      "Epoch 5/30 - Loss: 0.0387 - Acc: 0.9902 - F1: 0.9906\n",
      "Epoch 6/30 - Loss: 0.0351 - Acc: 0.9905 - F1: 0.9909\n",
      "Epoch 7/30 - Loss: 0.0335 - Acc: 0.9916 - F1: 0.9919\n",
      "Epoch 8/30 - Loss: 0.0315 - Acc: 0.9915 - F1: 0.9919\n",
      "Epoch 9/30 - Loss: 0.0290 - Acc: 0.9927 - F1: 0.9930\n",
      "Epoch 10/30 - Loss: 0.0286 - Acc: 0.9926 - F1: 0.9929\n",
      "Epoch 11/30 - Loss: 0.0275 - Acc: 0.9927 - F1: 0.9930\n",
      "Epoch 12/30 - Loss: 0.0262 - Acc: 0.9929 - F1: 0.9932\n",
      "Epoch 13/30 - Loss: 0.0238 - Acc: 0.9934 - F1: 0.9937\n",
      "Epoch 14/30 - Loss: 0.0240 - Acc: 0.9939 - F1: 0.9942\n",
      "Epoch 15/30 - Loss: 0.0212 - Acc: 0.9944 - F1: 0.9946\n",
      "Epoch 16/30 - Loss: 0.0218 - Acc: 0.9946 - F1: 0.9948\n",
      "Epoch 17/30 - Loss: 0.0213 - Acc: 0.9943 - F1: 0.9945\n",
      "Epoch 18/30 - Loss: 0.0193 - Acc: 0.9950 - F1: 0.9952\n",
      "Epoch 19/30 - Loss: 0.0186 - Acc: 0.9954 - F1: 0.9956\n",
      "Epoch 20/30 - Loss: 0.0186 - Acc: 0.9950 - F1: 0.9952\n",
      "Epoch 21/30 - Loss: 0.0164 - Acc: 0.9957 - F1: 0.9958\n",
      "Epoch 22/30 - Loss: 0.0158 - Acc: 0.9957 - F1: 0.9958\n",
      "Epoch 23/30 - Loss: 0.0155 - Acc: 0.9960 - F1: 0.9961\n",
      "Epoch 24/30 - Loss: 0.0155 - Acc: 0.9960 - F1: 0.9962\n",
      "Epoch 25/30 - Loss: 0.0139 - Acc: 0.9965 - F1: 0.9966\n",
      "Epoch 26/30 - Loss: 0.0137 - Acc: 0.9959 - F1: 0.9961\n",
      "Epoch 27/30 - Loss: 0.0132 - Acc: 0.9967 - F1: 0.9969\n",
      "Epoch 28/30 - Loss: 0.0129 - Acc: 0.9963 - F1: 0.9965\n",
      "Epoch 29/30 - Loss: 0.0111 - Acc: 0.9969 - F1: 0.9971\n",
      "Epoch 30/30 - Loss: 0.0116 - Acc: 0.9967 - F1: 0.9969\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9959\n",
      "Test Precision: 0.9957\n",
      "Test Recall: 0.9964\n",
      "Test F1 Score: 0.9961\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4264   20]\n",
      " [  17 4679]]\n",
      "\n",
      "--- Hyperparameter Combination 16/20 ---\n",
      "Parameters: {'patience': 3, 'learning_rate': 0.0005, 'hidden_sizes': [256, 128], 'epochs': 20, 'dropout': 0.5}\n",
      "Epoch 1/20 - Loss: 0.0990 - Acc: 0.9713 - F1: 0.9725\n",
      "Epoch 2/20 - Loss: 0.0285 - Acc: 0.9915 - F1: 0.9919\n",
      "Epoch 3/20 - Loss: 0.0215 - Acc: 0.9935 - F1: 0.9938\n",
      "Epoch 4/20 - Loss: 0.0160 - Acc: 0.9950 - F1: 0.9952\n",
      "Epoch 5/20 - Loss: 0.0133 - Acc: 0.9957 - F1: 0.9958\n",
      "Epoch 6/20 - Loss: 0.0111 - Acc: 0.9964 - F1: 0.9965\n",
      "Epoch 7/20 - Loss: 0.0087 - Acc: 0.9975 - F1: 0.9976\n",
      "Epoch 8/20 - Loss: 0.0082 - Acc: 0.9976 - F1: 0.9977\n",
      "Epoch 9/20 - Loss: 0.0064 - Acc: 0.9979 - F1: 0.9979\n",
      "Epoch 10/20 - Loss: 0.0061 - Acc: 0.9979 - F1: 0.9980\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9970\n",
      "Test Precision: 0.9979\n",
      "Test Recall: 0.9964\n",
      "Test F1 Score: 0.9971\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4274   10]\n",
      " [  17 4679]]\n",
      "\n",
      "--- Hyperparameter Combination 17/20 ---\n",
      "Parameters: {'patience': 7, 'learning_rate': 0.001, 'hidden_sizes': [256, 128], 'epochs': 40, 'dropout': 0.7}\n",
      "Epoch 1/40 - Loss: 0.0991 - Acc: 0.9641 - F1: 0.9658\n",
      "Epoch 2/40 - Loss: 0.0325 - Acc: 0.9908 - F1: 0.9912\n",
      "Epoch 3/40 - Loss: 0.0234 - Acc: 0.9930 - F1: 0.9933\n",
      "Epoch 4/40 - Loss: 0.0192 - Acc: 0.9940 - F1: 0.9942\n",
      "Epoch 5/40 - Loss: 0.0182 - Acc: 0.9944 - F1: 0.9946\n",
      "Epoch 6/40 - Loss: 0.0160 - Acc: 0.9945 - F1: 0.9948\n",
      "Epoch 7/40 - Loss: 0.0135 - Acc: 0.9955 - F1: 0.9957\n",
      "Epoch 8/40 - Loss: 0.0111 - Acc: 0.9964 - F1: 0.9965\n",
      "Epoch 9/40 - Loss: 0.0118 - Acc: 0.9963 - F1: 0.9965\n",
      "Epoch 10/40 - Loss: 0.0118 - Acc: 0.9962 - F1: 0.9963\n",
      "Epoch 11/40 - Loss: 0.0101 - Acc: 0.9967 - F1: 0.9969\n",
      "Epoch 12/40 - Loss: 0.0082 - Acc: 0.9973 - F1: 0.9974\n",
      "Epoch 13/40 - Loss: 0.0091 - Acc: 0.9970 - F1: 0.9972\n",
      "Epoch 14/40 - Loss: 0.0100 - Acc: 0.9970 - F1: 0.9972\n",
      "Epoch 15/40 - Loss: 0.0103 - Acc: 0.9965 - F1: 0.9966\n",
      "Epoch 16/40 - Loss: 0.0075 - Acc: 0.9975 - F1: 0.9976\n",
      "Epoch 17/40 - Loss: 0.0074 - Acc: 0.9979 - F1: 0.9980\n",
      "Epoch 18/40 - Loss: 0.0072 - Acc: 0.9976 - F1: 0.9977\n",
      "Epoch 19/40 - Loss: 0.0068 - Acc: 0.9977 - F1: 0.9978\n",
      "Epoch 20/40 - Loss: 0.0064 - Acc: 0.9980 - F1: 0.9981\n",
      "Epoch 21/40 - Loss: 0.0063 - Acc: 0.9980 - F1: 0.9981\n",
      "Epoch 22/40 - Loss: 0.0060 - Acc: 0.9977 - F1: 0.9978\n",
      "Epoch 23/40 - Loss: 0.0066 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 24/40 - Loss: 0.0069 - Acc: 0.9979 - F1: 0.9980\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9969\n",
      "Test Precision: 0.9966\n",
      "Test Recall: 0.9974\n",
      "Test F1 Score: 0.9970\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4268   16]\n",
      " [  12 4684]]\n",
      "\n",
      "--- Hyperparameter Combination 18/20 ---\n",
      "Parameters: {'patience': 7, 'learning_rate': 0.0005, 'hidden_sizes': [256, 128, 64], 'epochs': 30, 'dropout': 0.3}\n",
      "Epoch 1/30 - Loss: 0.0855 - Acc: 0.9730 - F1: 0.9745\n",
      "Epoch 2/30 - Loss: 0.0233 - Acc: 0.9925 - F1: 0.9928\n",
      "Epoch 3/30 - Loss: 0.0185 - Acc: 0.9943 - F1: 0.9945\n",
      "Epoch 4/30 - Loss: 0.0130 - Acc: 0.9959 - F1: 0.9961\n",
      "Epoch 5/30 - Loss: 0.0101 - Acc: 0.9966 - F1: 0.9968\n",
      "Epoch 6/30 - Loss: 0.0068 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 7/30 - Loss: 0.0060 - Acc: 0.9982 - F1: 0.9982\n",
      "Epoch 8/30 - Loss: 0.0045 - Acc: 0.9986 - F1: 0.9986\n",
      "Epoch 9/30 - Loss: 0.0044 - Acc: 0.9987 - F1: 0.9987\n",
      "Epoch 10/30 - Loss: 0.0049 - Acc: 0.9986 - F1: 0.9987\n",
      "Epoch 11/30 - Loss: 0.0027 - Acc: 0.9993 - F1: 0.9993\n",
      "Epoch 12/30 - Loss: 0.0044 - Acc: 0.9985 - F1: 0.9986\n",
      "Epoch 13/30 - Loss: 0.0026 - Acc: 0.9992 - F1: 0.9992\n",
      "Epoch 14/30 - Loss: 0.0026 - Acc: 0.9993 - F1: 0.9994\n",
      "Epoch 15/30 - Loss: 0.0026 - Acc: 0.9992 - F1: 0.9992\n",
      "Epoch 16/30 - Loss: 0.0018 - Acc: 0.9996 - F1: 0.9996\n",
      "Epoch 17/30 - Loss: 0.0025 - Acc: 0.9991 - F1: 0.9991\n",
      "Epoch 18/30 - Loss: 0.0026 - Acc: 0.9994 - F1: 0.9994\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9972\n",
      "Test Precision: 0.9977\n",
      "Test Recall: 0.9970\n",
      "Test F1 Score: 0.9973\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4273   11]\n",
      " [  14 4682]]\n",
      "New best model found!\n",
      "\n",
      "--- Hyperparameter Combination 19/20 ---\n",
      "Parameters: {'patience': 5, 'learning_rate': 0.005, 'hidden_sizes': [256, 128, 64], 'epochs': 40, 'dropout': 0.7}\n",
      "Epoch 1/40 - Loss: 0.0907 - Acc: 0.9697 - F1: 0.9708\n",
      "Epoch 2/40 - Loss: 0.0566 - Acc: 0.9873 - F1: 0.9879\n",
      "Epoch 3/40 - Loss: 0.0554 - Acc: 0.9889 - F1: 0.9894\n",
      "Epoch 4/40 - Loss: 0.0515 - Acc: 0.9885 - F1: 0.9890\n",
      "Epoch 5/40 - Loss: 0.0516 - Acc: 0.9901 - F1: 0.9905\n",
      "Epoch 6/40 - Loss: 0.0522 - Acc: 0.9909 - F1: 0.9913\n",
      "Epoch 7/40 - Loss: 0.0628 - Acc: 0.9901 - F1: 0.9905\n",
      "Epoch 8/40 - Loss: 0.0593 - Acc: 0.9896 - F1: 0.9900\n",
      "Epoch 9/40 - Loss: 0.0579 - Acc: 0.9882 - F1: 0.9886\n",
      "Epoch 10/40 - Loss: 0.0747 - Acc: 0.9909 - F1: 0.9913\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9955\n",
      "Test Precision: 0.9976\n",
      "Test Recall: 0.9938\n",
      "Test F1 Score: 0.9957\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       0.99      1.00      1.00      4284\n",
      "        Fake       1.00      0.99      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4273   11]\n",
      " [  29 4667]]\n",
      "\n",
      "--- Hyperparameter Combination 20/20 ---\n",
      "Parameters: {'patience': 5, 'learning_rate': 0.0001, 'hidden_sizes': [512, 256, 128], 'epochs': 20, 'dropout': 0.3}\n",
      "Epoch 1/20 - Loss: 0.1550 - Acc: 0.9575 - F1: 0.9600\n",
      "Epoch 2/20 - Loss: 0.0277 - Acc: 0.9913 - F1: 0.9916\n",
      "Epoch 3/20 - Loss: 0.0221 - Acc: 0.9929 - F1: 0.9932\n",
      "Epoch 4/20 - Loss: 0.0193 - Acc: 0.9932 - F1: 0.9935\n",
      "Epoch 5/20 - Loss: 0.0176 - Acc: 0.9943 - F1: 0.9946\n",
      "Epoch 6/20 - Loss: 0.0150 - Acc: 0.9950 - F1: 0.9952\n",
      "Epoch 7/20 - Loss: 0.0132 - Acc: 0.9957 - F1: 0.9958\n",
      "Epoch 8/20 - Loss: 0.0116 - Acc: 0.9962 - F1: 0.9964\n",
      "Epoch 9/20 - Loss: 0.0096 - Acc: 0.9968 - F1: 0.9969\n",
      "Epoch 10/20 - Loss: 0.0091 - Acc: 0.9968 - F1: 0.9970\n",
      "Epoch 11/20 - Loss: 0.0079 - Acc: 0.9975 - F1: 0.9976\n",
      "Epoch 12/20 - Loss: 0.0059 - Acc: 0.9982 - F1: 0.9982\n",
      "Epoch 13/20 - Loss: 0.0050 - Acc: 0.9985 - F1: 0.9986\n",
      "Epoch 14/20 - Loss: 0.0040 - Acc: 0.9986 - F1: 0.9987\n",
      "Epoch 15/20 - Loss: 0.0039 - Acc: 0.9987 - F1: 0.9988\n",
      "Epoch 16/20 - Loss: 0.0036 - Acc: 0.9987 - F1: 0.9988\n",
      "Epoch 17/20 - Loss: 0.0029 - Acc: 0.9991 - F1: 0.9991\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9976\n",
      "Test Precision: 0.9983\n",
      "Test Recall: 0.9970\n",
      "Test F1 Score: 0.9977\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4276    8]\n",
      " [  14 4682]]\n",
      "New best model found!\n",
      "\n",
      "Best Parameters: {'patience': 5, 'learning_rate': 0.0001, 'hidden_sizes': [512, 256, 128], 'epochs': 20, 'dropout': 0.3}\n",
      "Best F1: 0.9977\n",
      "\n",
      "Retraining the model with the best hyperparameters...\n",
      "Epoch 1/20 - Loss: 0.1624 - Acc: 0.9503 - F1: 0.9530\n",
      "Epoch 2/20 - Loss: 0.0277 - Acc: 0.9918 - F1: 0.9922\n",
      "Epoch 3/20 - Loss: 0.0225 - Acc: 0.9933 - F1: 0.9936\n",
      "Epoch 4/20 - Loss: 0.0203 - Acc: 0.9937 - F1: 0.9940\n",
      "Epoch 5/20 - Loss: 0.0163 - Acc: 0.9950 - F1: 0.9952\n",
      "Epoch 6/20 - Loss: 0.0143 - Acc: 0.9959 - F1: 0.9960\n",
      "Epoch 7/20 - Loss: 0.0134 - Acc: 0.9959 - F1: 0.9961\n",
      "Epoch 8/20 - Loss: 0.0109 - Acc: 0.9966 - F1: 0.9967\n",
      "Epoch 9/20 - Loss: 0.0095 - Acc: 0.9970 - F1: 0.9972\n",
      "Epoch 10/20 - Loss: 0.0071 - Acc: 0.9978 - F1: 0.9979\n",
      "Epoch 11/20 - Loss: 0.0067 - Acc: 0.9977 - F1: 0.9978\n",
      "Epoch 12/20 - Loss: 0.0066 - Acc: 0.9980 - F1: 0.9981\n",
      "Epoch 13/20 - Loss: 0.0052 - Acc: 0.9982 - F1: 0.9982\n",
      "Epoch 14/20 - Loss: 0.0040 - Acc: 0.9987 - F1: 0.9988\n",
      "Epoch 15/20 - Loss: 0.0040 - Acc: 0.9987 - F1: 0.9988\n",
      "Early stopping triggered.\n",
      "\n",
      "Final Evaluation on Test Set:\n",
      "Test Accuracy: 0.9962\n",
      "Test Precision: 0.9962\n",
      "Test Recall: 0.9966\n",
      "Test F1 Score: 0.9964\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4266   18]\n",
      " [  16 4680]]\n",
      "\n",
      "Best Model saved to best_ffnn_model_final.pth\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Hyperparameter Tuning with Randomized Search\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import random\n",
    "\n",
    "# Function for hyperparameter tuning using Randomized Search\n",
    "def randomized_hyperparameter_tuning(\n",
    "    model_class,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    param_distributions,\n",
    "    n_iter=20,\n",
    "    metric='f1'\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs randomized hyperparameter tuning.\n",
    "\n",
    "    Args:\n",
    "        model_class: The neural network class.\n",
    "        train_loader: DataLoader for training data.\n",
    "        test_loader: DataLoader for test data.\n",
    "        device: Device to run the model on ('cpu' or 'cuda').\n",
    "        param_distributions: Dictionary with hyperparameters to sample.\n",
    "        n_iter: Number of parameter settings sampled.\n",
    "        metric: Metric to optimize ('accuracy' or 'f1').\n",
    "\n",
    "    Returns:\n",
    "        best_params: The best hyperparameters found.\n",
    "        best_score: The best score achieved.\n",
    "    \"\"\"\n",
    "    # Generate random hyperparameter combinations\n",
    "    sampled_params = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=42))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    \n",
    "    for idx, params in enumerate(sampled_params):\n",
    "        print(f\"\\n--- Hyperparameter Combination {idx+1}/{n_iter} ---\")\n",
    "        print(f\"Parameters: {params}\")\n",
    "        \n",
    "        # Extract hyperparameters\n",
    "        lr = params.get('learning_rate', 0.001)\n",
    "        hidden_sizes = params.get('hidden_sizes', [128, 64])\n",
    "        dropout = params.get('dropout', 0.5)\n",
    "        epochs = params.get('epochs', 20)\n",
    "        patience = params.get('patience', 3)\n",
    "        \n",
    "        # Define the model\n",
    "        model = model_class(\n",
    "            input_size=X_train_emb.shape[1],\n",
    "            hidden_sizes=hidden_sizes,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Move model to device\n",
    "        model.to(device)\n",
    "        \n",
    "        # Define loss and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Initialize Early Stopping\n",
    "        early_stopping = EarlyStopping(patience=patience, min_delta=0.001)\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_loss = 0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            \n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item() * X_batch.size(0)\n",
    "                \n",
    "                preds = (outputs >= 0.5).float()\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y_batch.cpu().numpy())\n",
    "            \n",
    "            epoch_loss /= len(train_loader.dataset)\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "            epoch_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "            \n",
    "            print(f\"Epoch {epoch}/{epochs} - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.4f} - F1: {epoch_f1:.4f}\")\n",
    "            \n",
    "            # Check early stopping\n",
    "            current_score = epoch_f1 if metric == 'f1' else epoch_acc\n",
    "            early_stopping(current_score)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        print(\"Evaluating on test set...\")\n",
    "        acc, precision, recall, f1, cm, report = evaluate_model_detailed(model, test_loader, device)\n",
    "        \n",
    "        # Determine if this is the best model so far\n",
    "        score = f1 if metric == 'f1' else acc\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "            print(\"New best model found!\")\n",
    "    \n",
    "    print(f\"\\nBest Parameters: {best_params}\")\n",
    "    print(f\"Best {metric.upper()}: {best_score:.4f}\")\n",
    "    \n",
    "    return best_params, best_score\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001, 0.005],\n",
    "    'hidden_sizes': [\n",
    "        [128, 64],\n",
    "        [256, 128],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64],\n",
    "        [512, 256, 128]\n",
    "    ],\n",
    "    'dropout': [0.3, 0.5, 0.7],\n",
    "    'epochs': [20, 30, 40],\n",
    "    'patience': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Identify the best preprocessing-embedding combination from previous steps\n",
    "# Assuming 'Best Combination' is stored in best_combination variable\n",
    "# For demonstration, let's use the previously identified best_comb_key\n",
    "best_comb_key = best_combination['Combination']\n",
    "best_embed, best_prep = best_comb_key.split(' + ')\n",
    "print(f\"Selected Best Preprocessing: {best_prep}\")\n",
    "print(f\"Selected Best Embedding: {best_embed}\")\n",
    "\n",
    "# Extract the corresponding training and test data\n",
    "# Reapply the best preprocessing and embedding\n",
    "print(f\"\\nReapplying Best Preprocessing: {best_prep} and Embedding: {best_embed}\")\n",
    "best_processed_texts = processed_texts[best_prep]\n",
    "\n",
    "# Split the data\n",
    "X = best_processed_texts\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Apply the best embedding\n",
    "if best_embed == 'OneHot':\n",
    "    X_train_emb, X_test_emb, vectorizer = one_hot_encode(X_train, X_test, max_features=5000)\n",
    "elif best_embed == 'Word2Vec':\n",
    "    X_train_emb, X_test_emb, w2v_model = word2vec_embed(X_train, X_test, vector_size=100)\n",
    "elif best_embed == 'GloVe':\n",
    "    X_train_emb, X_test_emb = glove_embed(X_train, X_test, embeddings_glove, embedding_dim=100)\n",
    "elif best_embed == 'Doc2Vec':\n",
    "    X_train_emb, X_test_emb, d2v_model = doc2vec_embed(X_train, X_test, vector_size=100, window=5, min_count=1, epochs=20)\n",
    "elif best_embed == 'NaiveD2V':\n",
    "    X_train_emb, X_test_emb, naived2v_model = naived2v_embed(X_train, X_test, vector_size=100, window=5, min_count=1, epochs=20)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported embedding method.\")\n",
    "\n",
    "print(f\"Embedding {best_embed} shape: {X_train_emb.shape}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader, test_loader = create_dataloaders(X_train_emb, X_test_emb, y_train, y_test, batch_size=64)\n",
    "\n",
    "# Perform Randomized Hyperparameter Tuning\n",
    "print(\"\\nStarting Randomized Hyperparameter Tuning...\")\n",
    "best_params, best_score = randomized_hyperparameter_tuning(\n",
    "    model_class=FFNN,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    metric='f1'  # Optimize based on F1 Score\n",
    ")\n",
    "\n",
    "# Retrain the model with the best hyperparameters\n",
    "print(\"\\nRetraining the model with the best hyperparameters...\")\n",
    "best_lr = best_params['learning_rate']\n",
    "best_hidden_sizes = best_params['hidden_sizes']\n",
    "best_dropout = best_params['dropout']\n",
    "best_epochs = best_params['epochs']\n",
    "best_patience = best_params['patience']\n",
    "\n",
    "# Define the best model\n",
    "best_model = FFNN(\n",
    "    input_size=X_train_emb.shape[1],\n",
    "    hidden_sizes=best_hidden_sizes,\n",
    "    dropout=best_dropout\n",
    ")\n",
    "best_model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_lr)\n",
    "\n",
    "# Initialize Early Stopping\n",
    "early_stopping = EarlyStopping(patience=best_patience, min_delta=0.001)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_model.train()\n",
    "for epoch in range(1, best_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = best_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        preds = (outputs >= 0.5).float()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{best_epochs} - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.4f} - F1: {epoch_f1:.4f}\")\n",
    "    \n",
    "    # Check early stopping\n",
    "    current_score = epoch_f1\n",
    "    early_stopping(current_score)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Final Evaluation\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "final_acc, final_precision, final_recall, final_f1, final_cm, final_report = evaluate_model_detailed(best_model, test_loader, device)\n",
    "\n",
    "# Save the best model\n",
    "model_path = 'best_ffnn_model_final.pth'\n",
    "torch.save(best_model.state_dict(), model_path)\n",
    "print(f\"\\nBest Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b3fde119-5df0-454a-a4c4-06d35e50b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 14: Visualize Training Loss and Accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history, title='Training History'):\n",
    "    epochs = range(1, len(history['loss']) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "    # Plot Loss\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, history['loss'], label='Loss', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{title} - Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot Accuracy and F1 Score\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, history['accuracy'], label='Accuracy', color='green', marker='o')\n",
    "    plt.plot(epochs, history['f1'], label='F1 Score', color='red', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'{title} - Accuracy & F1 Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'history' from the final training loop is available\n",
    "plot_training_history(history, title='Best Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "62167269-ea96-48d8-bc3c-c1ced0b3e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of misclassified examples (Best Model): 34)\n",
      "\n",
      "Sample Misclassified True News (Best Model):\n",
      "[0.09165693074464798, 0.38286423683166504, 0.16...\n",
      "[0.9032797813415527, 0.028670432046055794, -0.3...\n",
      "\n",
      "Sample Misclassified Fake News (Best Model):\n",
      "[-0.04923251271247864, 0.5588398575782776, -0.7...\n",
      "[-0.22259099781513214, -0.8126096725463867, -0....\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Comprehensive Error Analysis for the Best Model\n",
    "\n",
    "def error_analysis(model, test_loader, X_test, y_test, embedding_name):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    # Create a DataFrame for analysis\n",
    "    analysis_df = pd.DataFrame({\n",
    "        'Text': X_test.tolist(),\n",
    "        'True Label': all_labels,\n",
    "        'Predicted Label': all_preds\n",
    "    })\n",
    "    \n",
    "    # Misclassified examples\n",
    "    misclassified = analysis_df[analysis_df['True Label'] != analysis_df['Predicted Label']]\n",
    "    print(f\"\\nNumber of misclassified examples ({embedding_name}): {len(misclassified)})\")\n",
    "    \n",
    "    # Display some misclassified examples\n",
    "    print(f\"\\nSample Misclassified True News ({embedding_name}):\")\n",
    "    print(misclassified[misclassified['True Label'] == 0]['Text'].iloc[:2].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nSample Misclassified Fake News ({embedding_name}):\")\n",
    "    print(misclassified[misclassified['True Label'] == 1]['Text'].iloc[:2].to_string(index=False))\n",
    "\n",
    "# Perform error analysis for the best model\n",
    "error_analysis(best_model, test_loader, X_test_emb, y_test, 'Best Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "af208a9c-e552-43de-91bd-02e1409c8d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Best Model Evaluation Metrics ===\n",
      "Accuracy: 0.9962\n",
      "Precision: 0.9962\n",
      "Recall: 0.9966\n",
      "F1 Score: 0.9964\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00      4284\n",
      "        Fake       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[4266   18]\n",
      " [  16 4680]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Hyperparameters ===\n",
      "patience: 5\n",
      "learning_rate: 0.0001\n",
      "hidden_sizes: [512, 256, 128]\n",
      "epochs: 20\n",
      "dropout: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Print and Visualize Statistics for the Best Model\n",
    "\n",
    "# 1. Print Evaluation Metrics\n",
    "print(\"=== Best Model Evaluation Metrics ===\")\n",
    "print(f\"Accuracy: {final_acc:.4f}\")\n",
    "print(f\"Precision: {final_precision:.4f}\")\n",
    "print(f\"Recall: {final_recall:.4f}\")\n",
    "print(f\"F1 Score: {final_f1:.4f}\")\n",
    "\n",
    "# 2. Print Classification Report\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(final_report)\n",
    "\n",
    "# 3. Print Confusion Matrix\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(final_cm)\n",
    "\n",
    "# 4. Visualize Confusion Matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(final_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['True', 'Fake'], yticklabels=['True', 'Fake'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 5. Print Best Hyperparameters\n",
    "print(\"\\n=== Best Hyperparameters ===\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79652eab-5fef-4ca9-bd37-78cd5a5485bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970face9-68e0-4f68-aa43-dba94e304969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d71b8a-e473-4f5a-ad00-d0f02d82aa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df821e9-e696-4ce1-9ad3-bdda1f205397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd81c3-c445-4543-84fd-395f3f23c8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c5e02-a370-4215-bc32-005f39321738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
